{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/KeD/Scripts/python/keiba/KeibaAI/keiba/keiba_main.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/KeD/Scripts/python/keiba/KeibaAI/keiba/keiba_main.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m roc_auc_score\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/KeD/Scripts/python/keiba/KeibaAI/keiba/keiba_main.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/KeD/Scripts/python/keiba/KeibaAI/keiba/keiba_main.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlgb\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/KeD/Scripts/python/keiba/KeibaAI/keiba/keiba_main.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/KeD/Scripts/python/keiba/KeibaAI/keiba/keiba_main.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbs4\u001b[39;00m \u001b[39mimport\u001b[39;00m BeautifulSoup\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import optuna.integration.lightgbm as lgb_o\n",
    "from itertools import combinations, permutations\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"    \n",
    "    Attributes:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        rawデータ\n",
    "    data_p : pd.DataFrame\n",
    "        preprocessing後のデータ\n",
    "    data_h : pd.DataFrame\n",
    "        merge_horse_results後のデータ\n",
    "    data_pe : pd.DataFrame\n",
    "        merge_peds後のデータ\n",
    "    data_c : pd.DataFrame\n",
    "        process_categorical後のデータ\n",
    "    no_peds: Numpy.array\n",
    "        merge_pedsを実行した時に、血統データが存在しなかった馬のhorse_id一覧\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = pd.DataFrame()\n",
    "        self.data_p = pd.DataFrame()\n",
    "        self.data_h = pd.DataFrame()\n",
    "        self.data_pe = pd.DataFrame()\n",
    "        self.data_c = pd.DataFrame()\n",
    "        \n",
    "    def merge_horse_results(self, hr, n_samples_list=[5, 9, 'all']):\n",
    "        \"\"\"\n",
    "        馬の過去成績データから、\n",
    "        n_samples_listで指定されたレース分の着順と賞金の平均を追加してdata_hに返す\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        hr : HorseResults\n",
    "            馬の過去成績データ\n",
    "        n_samples_list : list, default [5, 9, 'all']\n",
    "            過去何レース分追加するか\n",
    "        \"\"\"\n",
    "\n",
    "        self.data_h = self.data_p.copy()\n",
    "        for n_samples in n_samples_list:\n",
    "            self.data_h = hr.merge_all(self.data_h, n_samples=n_samples)\n",
    "            \n",
    "        #6/6追加： 馬の出走間隔追加\n",
    "        self.data_h['interval'] = (self.data_h['date'] - self.data_h['latest']).dt.days\n",
    "        self.data_h.drop(['開催', 'latest'], axis=1, inplace=True)\n",
    "        \n",
    "    def merge_peds(self, peds):\n",
    "        \"\"\"\n",
    "        5世代分血統データを追加してdata_peに返す\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        peds : Peds.peds_e\n",
    "            Pedsクラスで加工された血統データ。\n",
    "        \"\"\"\n",
    "\n",
    "        self.data_pe = \\\n",
    "            self.data_h.merge(peds, left_on='horse_id', right_index=True,\n",
    "                                                             how='left')\n",
    "        self.no_peds = self.data_pe[self.data_pe['peds_0'].isnull()]\\\n",
    "            ['horse_id'].unique()\n",
    "        if len(self.no_peds) > 0:\n",
    "            print('scrape peds at horse_id_list \"no_peds\"')\n",
    "            \n",
    "    def process_categorical(self, le_horse, le_jockey, results_m):\n",
    "        \"\"\"\n",
    "        カテゴリ変数を処理してdata_cに返す\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        le_horse : sklearn.preprocessing.LabelEncoder\n",
    "            horse_idを0始まりの整数に変換するLabelEncoderオブジェクト。\n",
    "        le_jockey : sklearn.preprocessing.LabelEncoder\n",
    "            jockey_idを0始まりの整数に変換するLabelEncoderオブジェクト。\n",
    "        results_m : Results.data_pe\n",
    "            ダミー変数化のとき、ResultsクラスとShutubaTableクラスで列を合わせるためのもの\n",
    "        \"\"\"\n",
    "\n",
    "        df = self.data_pe.copy()\n",
    "        \n",
    "        #ラベルエンコーディング。horse_id, jockey_idを0始まりの整数に変換\n",
    "        mask_horse = df['horse_id'].isin(le_horse.classes_)\n",
    "        new_horse_id = df['horse_id'].mask(mask_horse).dropna().unique()\n",
    "        le_horse.classes_ = np.concatenate([le_horse.classes_, new_horse_id])\n",
    "        df['horse_id'] = le_horse.transform(df['horse_id'])\n",
    "        mask_jockey = df['jockey_id'].isin(le_jockey.classes_)\n",
    "        new_jockey_id = df['jockey_id'].mask(mask_jockey).dropna().unique()\n",
    "        le_jockey.classes_ = np.concatenate([le_jockey.classes_, new_jockey_id])\n",
    "        df['jockey_id'] = le_jockey.transform(df['jockey_id'])\n",
    "        \n",
    "        #horse_id, jockey_idをpandasのcategory型に変換\n",
    "        df['horse_id'] = df['horse_id'].astype('category')\n",
    "        df['jockey_id'] = df['jockey_id'].astype('category')\n",
    "        \n",
    "        #そのほかのカテゴリ変数をpandasのcategory型に変換してからダミー変数化\n",
    "        #列を一定にするため\n",
    "        weathers = results_m['weather'].unique()\n",
    "        race_types = results_m['race_type'].unique()\n",
    "        ground_states = results_m['ground_state'].unique()\n",
    "        sexes = results_m['性'].unique()\n",
    "        df['weather'] = pd.Categorical(df['weather'], weathers)\n",
    "        df['race_type'] = pd.Categorical(df['race_type'], race_types)\n",
    "        df['ground_state'] = pd.Categorical(df['ground_state'], ground_states)\n",
    "        df['性'] = pd.Categorical(df['性'], sexes)\n",
    "        df = pd.get_dummies(df, columns=['weather', 'race_type', 'ground_state', '性'])\n",
    "        \n",
    "        self.data_c = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results(DataProcessor):\n",
    "    def __init__(self, results):\n",
    "        super(Results, self).__init__()\n",
    "        self.data = results\n",
    "        \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.read_pickle(path_list[0])\n",
    "        for path in path_list[1:]:\n",
    "            df = update_data(df, pd.read_pickle(path))\n",
    "        return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(race_id_list):\n",
    "        \"\"\"\n",
    "        レース結果データをスクレイピングする関数\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        race_id_list : list\n",
    "            レースIDのリスト\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        race_results_df : pandas.DataFrame\n",
    "            全レース結果データをまとめてDataFrame型にしたもの\n",
    "        \"\"\"\n",
    "\n",
    "        #race_idをkeyにしてDataFrame型を格納\n",
    "        race_results = {}\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "\n",
    "                html = requests.get(url)\n",
    "                html.encoding = \"EUC-JP\"\n",
    "\n",
    "                #メインとなるテーブルデータを取得\n",
    "                df = pd.read_html(html.text)[0]\n",
    "                # 列名に半角スペースがあれば除去する\n",
    "                df = df.rename(columns=lambda x: x.replace(' ', ''))\n",
    "\n",
    "                # 天候、レースの種類、コースの長さ、馬場の状態、日付をスクレイピング\n",
    "                soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "                texts = (\n",
    "                    soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[0].text\n",
    "                    + soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[1].text\n",
    "                )\n",
    "                info = re.findall(r'\\w+', texts)\n",
    "                for text in info:\n",
    "                    if text in [\"芝\", \"ダート\"]:\n",
    "                        df[\"race_type\"] = [text] * len(df)\n",
    "                    if \"障\" in text:\n",
    "                        df[\"race_type\"] = [\"障害\"] * len(df)\n",
    "                    if \"m\" in text:\n",
    "                        df[\"course_len\"] = [int(re.findall(r\"\\d+\", text)[-1])] * len(df) #20211212：[0]→[-1]に修正\n",
    "                    if text in [\"良\", \"稍重\", \"重\", \"不良\"]:\n",
    "                        df[\"ground_state\"] = [text] * len(df)\n",
    "                    if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                        df[\"weather\"] = [text] * len(df)\n",
    "                    if \"年\" in text:\n",
    "                        df[\"date\"] = [text] * len(df)\n",
    "\n",
    "                #馬ID、騎手IDをスクレイピング\n",
    "                horse_id_list = []\n",
    "                horse_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/horse\")}\n",
    "                )\n",
    "                for a in horse_a_list:\n",
    "                    horse_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                    horse_id_list.append(horse_id[0])\n",
    "                jockey_id_list = []\n",
    "                jockey_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/jockey\")}\n",
    "                )\n",
    "                for a in jockey_a_list:\n",
    "                    jockey_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                    jockey_id_list.append(jockey_id[0])\n",
    "                df[\"horse_id\"] = horse_id_list\n",
    "                df[\"jockey_id\"] = jockey_id_list\n",
    "\n",
    "                #インデックスをrace_idにする\n",
    "                df.index = [race_id] * len(df)\n",
    "\n",
    "                race_results[race_id] = df\n",
    "            #存在しないrace_idを飛ばす\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except AttributeError: #存在しないrace_idでAttributeErrorになるページもあるので追加\n",
    "                continue\n",
    "            #wifiの接続が切れた時などでも途中までのデータを返せるようにする\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            #Jupyterで停止ボタンを押した時の対処\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる\n",
    "        race_results_df = pd.concat([race_results[key] for key in race_results])\n",
    "\n",
    "        return race_results_df\n",
    "    \n",
    "    #前処理    \n",
    "    def preprocessing(self):\n",
    "        df = self.data.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "        df['rank'] = df['着順'].map(lambda x:1 if x<4 else 0)\n",
    "\n",
    "        # 性齢を性と年齢に分ける\n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0]\n",
    "        df[\"体重変化\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[1].str[:-1]\n",
    "        \n",
    "        #errors='coerce'で、\"計不\"など変換できない時に欠損値にする\n",
    "        df['体重'] = pd.to_numeric(df['体重'], errors='coerce')\n",
    "        df['体重変化'] = pd.to_numeric(df['体重変化'], errors='coerce')\n",
    "\n",
    "        # 単勝をfloatに変換\n",
    "        df[\"単勝\"] = df[\"単勝\"].astype(float)\n",
    "        # 距離は10の位を切り捨てる\n",
    "        df[\"course_len\"] = df[\"course_len\"].astype(float) // 100\n",
    "\n",
    "        # 不要な列を削除\n",
    "        df.drop([\"タイム\", \"着差\", \"調教師\", \"性齢\", \"馬体重\", '馬名', '騎手', '人気', '着順'],\n",
    "                axis=1, inplace=True)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "        \n",
    "        #開催場所\n",
    "        df['開催'] = df.index.map(lambda x:str(x)[4:6])\n",
    "        \n",
    "        #6/6出走数追加\n",
    "        df['n_horses'] = df.index.map(df.index.value_counts())\n",
    "\n",
    "        self.data_p = df\n",
    "    \n",
    "    #カテゴリ変数の処理\n",
    "    def process_categorical(self):\n",
    "        self.le_horse = LabelEncoder().fit(self.data_pe['horse_id'])\n",
    "        self.le_jockey = LabelEncoder().fit(self.data_pe['jockey_id'])\n",
    "        super().process_categorical(self.le_horse, self.le_jockey, self.data_pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShutubaTable(DataProcessor):\n",
    "    def __init__(self, shutuba_tables):\n",
    "        super(ShutubaTable, self).__init__()\n",
    "        self.data = shutuba_tables\n",
    "    \n",
    "    @classmethod\n",
    "    def scrape(cls, race_id_list, date):\n",
    "        data = pd.DataFrame()\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            time.sleep(1)\n",
    "            url = 'https://race.netkeiba.com/race/shutuba.html?race_id=' + race_id\n",
    "\n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "\n",
    "            df = pd.read_html(html.text)[0]\n",
    "            # 列名に半角スペースがあれば除去する\n",
    "            df = df.rename(columns=lambda x: x.replace(' ', ''))\n",
    "            df = df.T.reset_index(level=0, drop=True).T\n",
    "\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "            texts = soup.find('div', attrs={'class': 'RaceData01'}).text\n",
    "            texts = re.findall(r'\\w+', texts)\n",
    "            for text in texts:\n",
    "                if 'm' in text:\n",
    "                    df['course_len'] = [int(re.findall(r'\\d+', text)[-1])] * len(df) #20211212：[0]→[-1]に修正\n",
    "                if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                    df[\"weather\"] = [text] * len(df)\n",
    "                if text in [\"良\", \"稍重\", \"重\"]:\n",
    "                    df[\"ground_state\"] = [text] * len(df)\n",
    "                if '不' in text:\n",
    "                    df[\"ground_state\"] = ['不良'] * len(df)\n",
    "                # 2020/12/13追加\n",
    "                if '稍' in text:\n",
    "                    df[\"ground_state\"] = ['稍重'] * len(df)\n",
    "                if '芝' in text:\n",
    "                    df['race_type'] = ['芝'] * len(df)\n",
    "                if '障' in text:\n",
    "                    df['race_type'] = ['障害'] * len(df)\n",
    "                if 'ダ' in text:\n",
    "                    df['race_type'] = ['ダート'] * len(df)\n",
    "            df['date'] = [date] * len(df)\n",
    "\n",
    "            # horse_id\n",
    "            horse_id_list = []\n",
    "            horse_td_list = soup.find_all(\"td\", attrs={'class': 'HorseInfo'})\n",
    "            for td in horse_td_list:\n",
    "                horse_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                horse_id_list.append(horse_id)\n",
    "            # jockey_id\n",
    "            jockey_id_list = []\n",
    "            jockey_td_list = soup.find_all(\"td\", attrs={'class': 'Jockey'})\n",
    "            for td in jockey_td_list:\n",
    "                jockey_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                jockey_id_list.append(jockey_id)\n",
    "            df['horse_id'] = horse_id_list\n",
    "            df['jockey_id'] = jockey_id_list\n",
    "\n",
    "            df.index = [race_id] * len(df)\n",
    "            data = pd.concat([data, df])\n",
    "        return cls(data)\n",
    "             \n",
    "    #前処理            \n",
    "    def preprocessing(self):\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        df = df[df[\"馬体重(増減)\"] != '--']\n",
    "        df[\"体重\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "        df[\"体重変化\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[1].str[:-1]\n",
    "        # 2020/12/13追加：増減が「前計不」などのとき欠損値にする\n",
    "        df['体重変化'] = pd.to_numeric(df['体重変化'], errors='coerce')\n",
    "        \n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        \n",
    "        df['枠'] = df['枠'].astype(int)\n",
    "        df['馬番'] = df['馬番'].astype(int)\n",
    "        df['斤量'] = df['斤量'].astype(int)\n",
    "        df['開催'] = df.index.map(lambda x:str(x)[4:6])\n",
    "        \n",
    "        #6/6出走数追加\n",
    "        df['n_horses'] = df.index.map(df.index.value_counts())\n",
    "\n",
    "        # 距離は10の位を切り捨てる\n",
    "        df[\"course_len\"] = df[\"course_len\"].astype(float) // 100\n",
    "\n",
    "        # 使用する列を選択\n",
    "        df = df[['枠', '馬番', '斤量', 'course_len', 'weather','race_type',\n",
    "        'ground_state', 'date', 'horse_id', 'jockey_id', '性', '年齢',\n",
    "       '体重', '体重変化', '開催', 'n_horses']]\n",
    "        \n",
    "        self.data_p = df.rename(columns={'枠': '枠番'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseResults:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付', '着順', '賞金', '着差', '通過', '開催', '距離']]\n",
    "        self.preprocessing()\n",
    "    \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.read_pickle(path_list[0])\n",
    "        for path in path_list[1:]:\n",
    "            df = update_data(df, pd.read_pickle(path))\n",
    "        return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(horse_id_list):\n",
    "        \"\"\"\n",
    "        馬の過去成績データをスクレイピングする関数\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        horse_id_list : list\n",
    "            馬IDのリスト\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        horse_results_df : pandas.DataFrame\n",
    "            全馬の過去成績データをまとめてDataFrame型にしたもの\n",
    "        \"\"\"\n",
    "\n",
    "        #horse_idをkeyにしてDataFrame型を格納\n",
    "        horse_results = {}\n",
    "        for horse_id in tqdm(horse_id_list):\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                url = 'https://db.netkeiba.com/horse/' + horse_id\n",
    "                df = pd.read_html(url)[3]\n",
    "                #受賞歴がある馬の場合、3番目に受賞歴テーブルが来るため、4番目のデータを取得する\n",
    "                if df.columns[0]=='受賞歴':\n",
    "                    df = pd.read_html(url)[4]\n",
    "                df.index = [horse_id] * len(df)\n",
    "                horse_results[horse_id] = df\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる        \n",
    "        horse_results_df = pd.concat([horse_results[key] for key in horse_results])\n",
    "\n",
    "        return horse_results_df\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        df = self.horse_results.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"日付\"])\n",
    "        df.drop(['日付'], axis=1, inplace=True)\n",
    "        \n",
    "        #賞金のNaNを0で埋める\n",
    "        df['賞金'].fillna(0, inplace=True)\n",
    "        \n",
    "        #1着の着差を0にする\n",
    "        df['着差'] = df['着差'].map(lambda x: 0 if x<0 else x)\n",
    "        \n",
    "        #レース展開データ\n",
    "        #n=1: 最初のコーナー位置, n=4: 最終コーナー位置\n",
    "        def corner(x, n):\n",
    "            if type(x) != str:\n",
    "                return x\n",
    "            elif n==4:\n",
    "                return int(re.findall(r'\\d+', x)[-1])\n",
    "            elif n==1:\n",
    "                return int(re.findall(r'\\d+', x)[0])\n",
    "        df['first_corner'] = df['通過'].map(lambda x: corner(x, 1))\n",
    "        df['final_corner'] = df['通過'].map(lambda x: corner(x, 4))\n",
    "        \n",
    "        df['final_to_rank'] = df['final_corner'] - df['着順']\n",
    "        df['first_to_rank'] = df['first_corner'] - df['着順']\n",
    "        df['first_to_final'] = df['first_corner'] - df['final_corner']\n",
    "        \n",
    "        #開催場所\n",
    "        df['開催'] = df['開催'].str.extract(r'(\\D+)')[0].map(place_dict).fillna('11')\n",
    "        #race_type\n",
    "        df['race_type'] = df['距離'].str.extract(r'(\\D+)')[0].map(race_type_dict)\n",
    "        #距離は10の位を切り捨てる\n",
    "        #一部の馬で欠損値があり、intに変換できないためfloatに変換する\n",
    "        df['course_len'] = df['距離'].str.extract(r'(\\d+)').astype(float) // 100\n",
    "        df.drop(['距離'], axis=1, inplace=True)\n",
    "        #インデックス名を与える\n",
    "        df.index.name = 'horse_id'\n",
    "        \n",
    "        self.horse_results = df\n",
    "        self.target_list = ['着順', '賞金', '着差', 'first_corner', 'final_corner',\n",
    "                            'first_to_rank', 'first_to_final','final_to_rank']\n",
    "    \n",
    "    #n_samplesレース分馬ごとに平均する\n",
    "    def average(self, horse_id_list, date, n_samples='all'):\n",
    "        target_df = self.horse_results.query('index in @horse_id_list')\n",
    "        \n",
    "        #過去何走分取り出すか指定\n",
    "        if n_samples == 'all':\n",
    "            filtered_df = target_df[target_df['date'] < date]\n",
    "        elif n_samples > 0:\n",
    "            filtered_df = target_df[target_df['date'] < date].\\\n",
    "                sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "        else:\n",
    "            raise Exception('n_samples must be >0')\n",
    "        \n",
    "        #集計して辞書型に入れる\n",
    "        self.average_dict = {}\n",
    "        self.average_dict['non_category'] = filtered_df.groupby(level=0)[self.target_list].mean()\\\n",
    "            .add_suffix('_{}R'.format(n_samples))\n",
    "        for column in ['course_len', 'race_type', '開催']:\n",
    "            self.average_dict[column] = filtered_df.groupby(['horse_id', column])\\\n",
    "                [self.target_list].mean().add_suffix('_{}_{}R'.format(column, n_samples))\n",
    "\n",
    "        #6/6追加: 馬の出走間隔追加のために、全レースの日付を変数latestに格納\n",
    "        if n_samples == 5:\n",
    "            self.latest = filtered_df.groupby('horse_id')['date'].max().rename('latest')\n",
    "    \n",
    "    def merge(self, results, date, n_samples='all'):\n",
    "        df = results[results['date']==date]\n",
    "        horse_id_list = df['horse_id']\n",
    "        self.average(horse_id_list, date, n_samples)\n",
    "        merged_df = df.merge(self.average_dict['non_category'], left_on='horse_id',\n",
    "                             right_index=True, how='left')\n",
    "        for column in ['course_len','race_type', '開催']:\n",
    "            merged_df = merged_df.merge(self.average_dict[column], \n",
    "                                        left_on=['horse_id', column],\n",
    "                                        right_index=True, how='left')\n",
    "\n",
    "        #6/6追加：馬の出走間隔追加のために、全レースの日付を変数latestに格納\n",
    "        if n_samples == 5:\n",
    "            merged_df = merged_df.merge(self.latest, left_on='horse_id',\n",
    "                             right_index=True, how='left')\n",
    "        return merged_df\n",
    "    \n",
    "    def merge_all(self, results, n_samples='all'):\n",
    "        date_list = results['date'].unique()\n",
    "        merged_df = pd.concat([self.merge(results, date, n_samples) for date in tqdm(date_list)])\n",
    "        return merged_df\n",
    "\n",
    "#開催場所をidに変換するための辞書型\n",
    "place_dict = {\n",
    "    '札幌':'01',  '函館':'02',  '福島':'03',  '新潟':'04',  '東京':'05', \n",
    "    '中山':'06',  '中京':'07',  '京都':'08',  '阪神':'09',  '小倉':'10'\n",
    "}\n",
    "\n",
    "#レースタイプをレース結果データと整合させるための辞書型\n",
    "race_type_dict = {\n",
    "    '芝': '芝', 'ダ': 'ダート', '障': '障害'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Peds:\n",
    "    def __init__(self, peds):\n",
    "        self.peds = peds\n",
    "        self.peds_e = pd.DataFrame() #after label encoding and transforming into category\n",
    "    \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.read_pickle(path_list[0])\n",
    "        for path in path_list[1:]:\n",
    "            df = update_data(df, pd.read_pickle(path))\n",
    "        return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(horse_id_list):\n",
    "        \"\"\"\n",
    "        血統データをスクレイピングする関数\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        horse_id_list : list\n",
    "            馬IDのリスト\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        peds_df : pandas.DataFrame\n",
    "            全血統データをまとめてDataFrame型にしたもの\n",
    "        \"\"\"\n",
    "\n",
    "        peds_dict = {}\n",
    "        for horse_id in tqdm(horse_id_list):\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/horse/ped/\" + horse_id\n",
    "                df = pd.read_html(url)[0]\n",
    "\n",
    "                #重複を削除して1列のSeries型データに直す\n",
    "                generations = {}\n",
    "                for i in reversed(range(5)):\n",
    "                    generations[i] = df[i]\n",
    "                    df.drop([i], axis=1, inplace=True)\n",
    "                    df = df.drop_duplicates()\n",
    "                ped = pd.concat([generations[i] for i in range(5)]).rename(horse_id)\n",
    "\n",
    "                peds_dict[horse_id] = ped.reset_index(drop=True)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #列名をpeds_0, ..., peds_61にする\n",
    "        peds_df = pd.concat([peds_dict[key] for key in peds_dict], axis=1).T.add_prefix('peds_')\n",
    "\n",
    "        return peds_df\n",
    "    \n",
    "    def encode(self):\n",
    "        df = self.peds.copy()\n",
    "        for column in df.columns:\n",
    "            df[column] = LabelEncoder().fit_transform(df[column].fillna('Na'))\n",
    "        self.peds_e = df.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(old, new):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    old : pandas.DataFrame\n",
    "        古いデータ\n",
    "    new : pandas.DataFrame\n",
    "        新しいデータ\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_old = old[~old.index.isin(new.index)]\n",
    "    return pd.concat([filtered_old, new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = HorseResults.read_pickle(['beta/horse_result.pickle'])\n",
    "# r.merge_horse_results(hr, n_samples_list=[5, 9, 'all'])\n",
    "# r.data_h.head() #jupyterで出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peds_0</th>\n",
       "      <th>peds_1</th>\n",
       "      <th>peds_2</th>\n",
       "      <th>peds_3</th>\n",
       "      <th>peds_4</th>\n",
       "      <th>peds_5</th>\n",
       "      <th>peds_6</th>\n",
       "      <th>peds_7</th>\n",
       "      <th>peds_8</th>\n",
       "      <th>peds_9</th>\n",
       "      <th>...</th>\n",
       "      <th>peds_52</th>\n",
       "      <th>peds_53</th>\n",
       "      <th>peds_54</th>\n",
       "      <th>peds_55</th>\n",
       "      <th>peds_56</th>\n",
       "      <th>peds_57</th>\n",
       "      <th>peds_58</th>\n",
       "      <th>peds_59</th>\n",
       "      <th>peds_60</th>\n",
       "      <th>peds_61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015100713</th>\n",
       "      <td>540</td>\n",
       "      <td>9496</td>\n",
       "      <td>218</td>\n",
       "      <td>487</td>\n",
       "      <td>821</td>\n",
       "      <td>7111</td>\n",
       "      <td>50</td>\n",
       "      <td>224</td>\n",
       "      <td>321</td>\n",
       "      <td>598</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>906</td>\n",
       "      <td>273</td>\n",
       "      <td>508</td>\n",
       "      <td>716</td>\n",
       "      <td>1293</td>\n",
       "      <td>343</td>\n",
       "      <td>430</td>\n",
       "      <td>1003</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015103211</th>\n",
       "      <td>787</td>\n",
       "      <td>6004</td>\n",
       "      <td>202</td>\n",
       "      <td>432</td>\n",
       "      <td>416</td>\n",
       "      <td>7004</td>\n",
       "      <td>63</td>\n",
       "      <td>270</td>\n",
       "      <td>326</td>\n",
       "      <td>597</td>\n",
       "      <td>...</td>\n",
       "      <td>285</td>\n",
       "      <td>331</td>\n",
       "      <td>28</td>\n",
       "      <td>305</td>\n",
       "      <td>385</td>\n",
       "      <td>96</td>\n",
       "      <td>117</td>\n",
       "      <td>1231</td>\n",
       "      <td>832</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015103578</th>\n",
       "      <td>786</td>\n",
       "      <td>1061</td>\n",
       "      <td>202</td>\n",
       "      <td>432</td>\n",
       "      <td>930</td>\n",
       "      <td>8318</td>\n",
       "      <td>63</td>\n",
       "      <td>270</td>\n",
       "      <td>326</td>\n",
       "      <td>597</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>612</td>\n",
       "      <td>135</td>\n",
       "      <td>523</td>\n",
       "      <td>455</td>\n",
       "      <td>554</td>\n",
       "      <td>343</td>\n",
       "      <td>690</td>\n",
       "      <td>1720</td>\n",
       "      <td>4388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015101520</th>\n",
       "      <td>707</td>\n",
       "      <td>4170</td>\n",
       "      <td>218</td>\n",
       "      <td>427</td>\n",
       "      <td>743</td>\n",
       "      <td>4208</td>\n",
       "      <td>50</td>\n",
       "      <td>224</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>165</td>\n",
       "      <td>861</td>\n",
       "      <td>29</td>\n",
       "      <td>291</td>\n",
       "      <td>438</td>\n",
       "      <td>309</td>\n",
       "      <td>343</td>\n",
       "      <td>1425</td>\n",
       "      <td>51</td>\n",
       "      <td>2591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015101217</th>\n",
       "      <td>819</td>\n",
       "      <td>3347</td>\n",
       "      <td>204</td>\n",
       "      <td>330</td>\n",
       "      <td>823</td>\n",
       "      <td>5310</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>202</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>456</td>\n",
       "      <td>45</td>\n",
       "      <td>135</td>\n",
       "      <td>523</td>\n",
       "      <td>455</td>\n",
       "      <td>554</td>\n",
       "      <td>633</td>\n",
       "      <td>1510</td>\n",
       "      <td>1582</td>\n",
       "      <td>3954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020106734</th>\n",
       "      <td>734</td>\n",
       "      <td>10852</td>\n",
       "      <td>44</td>\n",
       "      <td>94</td>\n",
       "      <td>87</td>\n",
       "      <td>3593</td>\n",
       "      <td>32</td>\n",
       "      <td>229</td>\n",
       "      <td>95</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>398</td>\n",
       "      <td>172</td>\n",
       "      <td>170</td>\n",
       "      <td>514</td>\n",
       "      <td>752</td>\n",
       "      <td>121</td>\n",
       "      <td>202</td>\n",
       "      <td>133</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020104905</th>\n",
       "      <td>519</td>\n",
       "      <td>8637</td>\n",
       "      <td>270</td>\n",
       "      <td>530</td>\n",
       "      <td>1022</td>\n",
       "      <td>3597</td>\n",
       "      <td>140</td>\n",
       "      <td>53</td>\n",
       "      <td>298</td>\n",
       "      <td>638</td>\n",
       "      <td>...</td>\n",
       "      <td>249</td>\n",
       "      <td>536</td>\n",
       "      <td>85</td>\n",
       "      <td>54</td>\n",
       "      <td>209</td>\n",
       "      <td>424</td>\n",
       "      <td>346</td>\n",
       "      <td>1549</td>\n",
       "      <td>149</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020103477</th>\n",
       "      <td>764</td>\n",
       "      <td>7221</td>\n",
       "      <td>227</td>\n",
       "      <td>657</td>\n",
       "      <td>1012</td>\n",
       "      <td>9219</td>\n",
       "      <td>132</td>\n",
       "      <td>275</td>\n",
       "      <td>284</td>\n",
       "      <td>663</td>\n",
       "      <td>...</td>\n",
       "      <td>401</td>\n",
       "      <td>109</td>\n",
       "      <td>135</td>\n",
       "      <td>221</td>\n",
       "      <td>534</td>\n",
       "      <td>985</td>\n",
       "      <td>285</td>\n",
       "      <td>686</td>\n",
       "      <td>189</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020100674</th>\n",
       "      <td>774</td>\n",
       "      <td>4729</td>\n",
       "      <td>202</td>\n",
       "      <td>515</td>\n",
       "      <td>977</td>\n",
       "      <td>4836</td>\n",
       "      <td>63</td>\n",
       "      <td>270</td>\n",
       "      <td>309</td>\n",
       "      <td>540</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>364</td>\n",
       "      <td>85</td>\n",
       "      <td>54</td>\n",
       "      <td>209</td>\n",
       "      <td>424</td>\n",
       "      <td>443</td>\n",
       "      <td>592</td>\n",
       "      <td>832</td>\n",
       "      <td>2203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020106815</th>\n",
       "      <td>613</td>\n",
       "      <td>6191</td>\n",
       "      <td>176</td>\n",
       "      <td>366</td>\n",
       "      <td>742</td>\n",
       "      <td>5300</td>\n",
       "      <td>24</td>\n",
       "      <td>194</td>\n",
       "      <td>187</td>\n",
       "      <td>447</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>416</td>\n",
       "      <td>150</td>\n",
       "      <td>145</td>\n",
       "      <td>466</td>\n",
       "      <td>900</td>\n",
       "      <td>304</td>\n",
       "      <td>570</td>\n",
       "      <td>1114</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36118 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           peds_0 peds_1 peds_2 peds_3 peds_4 peds_5 peds_6 peds_7 peds_8   \n",
       "2015100713    540   9496    218    487    821   7111     50    224    321  \\\n",
       "2015103211    787   6004    202    432    416   7004     63    270    326   \n",
       "2015103578    786   1061    202    432    930   8318     63    270    326   \n",
       "2015101520    707   4170    218    427    743   4208     50    224      9   \n",
       "2015101217    819   3347    204    330    823   5310     63      2    202   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2020106734    734  10852     44     94     87   3593     32    229     95   \n",
       "2020104905    519   8637    270    530   1022   3597    140     53    298   \n",
       "2020103477    764   7221    227    657   1012   9219    132    275    284   \n",
       "2020100674    774   4729    202    515    977   4836     63    270    309   \n",
       "2020106815    613   6191    176    366    742   5300     24    194    187   \n",
       "\n",
       "           peds_9  ... peds_52 peds_53 peds_54 peds_55 peds_56 peds_57   \n",
       "2015100713    598  ...     194     906     273     508     716    1293  \\\n",
       "2015103211    597  ...     285     331      28     305     385      96   \n",
       "2015103578    597  ...      76     612     135     523     455     554   \n",
       "2015101520     54  ...     165     861      29     291     438     309   \n",
       "2015101217    130  ...     456      45     135     523     455     554   \n",
       "...           ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "2020106734    196  ...      27     398     172     170     514     752   \n",
       "2020104905    638  ...     249     536      85      54     209     424   \n",
       "2020103477    663  ...     401     109     135     221     534     985   \n",
       "2020100674    540  ...      64     364      85      54     209     424   \n",
       "2020106815    447  ...     226     416     150     145     466     900   \n",
       "\n",
       "           peds_58 peds_59 peds_60 peds_61  \n",
       "2015100713     343     430    1003    1290  \n",
       "2015103211     117    1231     832    3001  \n",
       "2015103578     343     690    1720    4388  \n",
       "2015101520     343    1425      51    2591  \n",
       "2015101217     633    1510    1582    3954  \n",
       "...            ...     ...     ...     ...  \n",
       "2020106734     121     202     133    1675  \n",
       "2020104905     346    1549     149     234  \n",
       "2020103477     285     686     189    1477  \n",
       "2020100674     443     592     832    2203  \n",
       "2020106815     304     570    1114     910  \n",
       "\n",
       "[36118 rows x 62 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Peds.read_pickle(['beta/horse_peds.pickle'])\n",
    "p.encode()\n",
    "p.peds_e #jupyterで出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>weather</th>\n",
       "      <th>race_type</th>\n",
       "      <th>ground_state</th>\n",
       "      <th>date</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>性</th>\n",
       "      <th>年齢</th>\n",
       "      <th>体重</th>\n",
       "      <th>体重変化</th>\n",
       "      <th>開催</th>\n",
       "      <th>n_horses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015100713</td>\n",
       "      <td>01091</td>\n",
       "      <td>1</td>\n",
       "      <td>牝</td>\n",
       "      <td>2</td>\n",
       "      <td>406</td>\n",
       "      <td>-4</td>\n",
       "      <td>01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015103211</td>\n",
       "      <td>05339</td>\n",
       "      <td>1</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>484</td>\n",
       "      <td>-4</td>\n",
       "      <td>01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015103578</td>\n",
       "      <td>01014</td>\n",
       "      <td>1</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>450</td>\n",
       "      <td>-16</td>\n",
       "      <td>01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015101520</td>\n",
       "      <td>00663</td>\n",
       "      <td>0</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>442</td>\n",
       "      <td>-10</td>\n",
       "      <td>01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015101217</td>\n",
       "      <td>01153</td>\n",
       "      <td>0</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>472</td>\n",
       "      <td>-18</td>\n",
       "      <td>01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              枠番  馬番    斤量    単勝  course_len weather race_type ground_state   \n",
       "201701010101   3   3  54.0   3.0        18.0       晴         芝            良  \\\n",
       "201701010101   5   5  54.0   1.5        18.0       晴         芝            良   \n",
       "201701010101   7   7  54.0   6.2        18.0       晴         芝            良   \n",
       "201701010101   1   1  54.0  31.1        18.0       晴         芝            良   \n",
       "201701010101   2   2  53.0  22.8        18.0       晴         芝            良   \n",
       "\n",
       "                   date    horse_id jockey_id  rank  性  年齢   体重  体重変化  開催   \n",
       "201701010101 2017-07-29  2015100713     01091     1  牝   2  406    -4  01  \\\n",
       "201701010101 2017-07-29  2015103211     05339     1  牡   2  484    -4  01   \n",
       "201701010101 2017-07-29  2015103578     01014     1  牡   2  450   -16  01   \n",
       "201701010101 2017-07-29  2015101520     00663     0  牡   2  442   -10  01   \n",
       "201701010101 2017-07-29  2015101217     01153     0  牡   2  472   -18  01   \n",
       "\n",
       "              n_horses  \n",
       "201701010101         7  \n",
       "201701010101         7  \n",
       "201701010101         7  \n",
       "201701010101         7  \n",
       "201701010101         7  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = Results.read_pickle(['beta/race.pickle'])\n",
    "r.preprocessing()\n",
    "r.data_p.head() #jupyterで出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19e53aa497346c29dd8605b6bdcf6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4a7f8995744554b5c9c628f0718f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e676c203fca464d984c77884d74eb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>weather</th>\n",
       "      <th>race_type</th>\n",
       "      <th>ground_state</th>\n",
       "      <th>date</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>...</th>\n",
       "      <th>final_to_rank_race_type_allR</th>\n",
       "      <th>着順_開催_allR</th>\n",
       "      <th>賞金_開催_allR</th>\n",
       "      <th>着差_開催_allR</th>\n",
       "      <th>first_corner_開催_allR</th>\n",
       "      <th>final_corner_開催_allR</th>\n",
       "      <th>first_to_rank_開催_allR</th>\n",
       "      <th>first_to_final_開催_allR</th>\n",
       "      <th>final_to_rank_開催_allR</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015100713</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015103211</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015103578</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015101520</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015101217</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              枠番  馬番    斤量    単勝  course_len weather race_type ground_state   \n",
       "201701010101   3   3  54.0   3.0        18.0       晴         芝            良  \\\n",
       "201701010101   5   5  54.0   1.5        18.0       晴         芝            良   \n",
       "201701010101   7   7  54.0   6.2        18.0       晴         芝            良   \n",
       "201701010101   1   1  54.0  31.1        18.0       晴         芝            良   \n",
       "201701010101   2   2  53.0  22.8        18.0       晴         芝            良   \n",
       "\n",
       "                   date    horse_id  ... final_to_rank_race_type_allR   \n",
       "201701010101 2017-07-29  2015100713  ...                         -0.5  \\\n",
       "201701010101 2017-07-29  2015103211  ...                          3.5   \n",
       "201701010101 2017-07-29  2015103578  ...                         -1.0   \n",
       "201701010101 2017-07-29  2015101520  ...                         -1.0   \n",
       "201701010101 2017-07-29  2015101217  ...                         -2.0   \n",
       "\n",
       "              着順_開催_allR 賞金_開催_allR  着差_開催_allR  first_corner_開催_allR   \n",
       "201701010101         NaN        NaN         NaN                   NaN  \\\n",
       "201701010101         NaN        NaN         NaN                   NaN   \n",
       "201701010101         NaN        NaN         NaN                   NaN   \n",
       "201701010101         NaN        NaN         NaN                   NaN   \n",
       "201701010101         NaN        NaN         NaN                   NaN   \n",
       "\n",
       "              final_corner_開催_allR  first_to_rank_開催_allR   \n",
       "201701010101                   NaN                    NaN  \\\n",
       "201701010101                   NaN                    NaN   \n",
       "201701010101                   NaN                    NaN   \n",
       "201701010101                   NaN                    NaN   \n",
       "201701010101                   NaN                    NaN   \n",
       "\n",
       "              first_to_final_開催_allR  final_to_rank_開催_allR  interval  \n",
       "201701010101                     NaN                    NaN      20.0  \n",
       "201701010101                     NaN                    NaN      35.0  \n",
       "201701010101                     NaN                    NaN      14.0  \n",
       "201701010101                     NaN                    NaN      13.0  \n",
       "201701010101                     NaN                    NaN      27.0  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.merge_horse_results(hr, n_samples_list=[5, 9, 'all'])\n",
    "r.data_h.head() #jupyterで出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>weather</th>\n",
       "      <th>race_type</th>\n",
       "      <th>ground_state</th>\n",
       "      <th>date</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>...</th>\n",
       "      <th>peds_52</th>\n",
       "      <th>peds_53</th>\n",
       "      <th>peds_54</th>\n",
       "      <th>peds_55</th>\n",
       "      <th>peds_56</th>\n",
       "      <th>peds_57</th>\n",
       "      <th>peds_58</th>\n",
       "      <th>peds_59</th>\n",
       "      <th>peds_60</th>\n",
       "      <th>peds_61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015100713</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>906</td>\n",
       "      <td>273</td>\n",
       "      <td>508</td>\n",
       "      <td>716</td>\n",
       "      <td>1293</td>\n",
       "      <td>343</td>\n",
       "      <td>430</td>\n",
       "      <td>1003</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015103211</td>\n",
       "      <td>...</td>\n",
       "      <td>285</td>\n",
       "      <td>331</td>\n",
       "      <td>28</td>\n",
       "      <td>305</td>\n",
       "      <td>385</td>\n",
       "      <td>96</td>\n",
       "      <td>117</td>\n",
       "      <td>1231</td>\n",
       "      <td>832</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015103578</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>612</td>\n",
       "      <td>135</td>\n",
       "      <td>523</td>\n",
       "      <td>455</td>\n",
       "      <td>554</td>\n",
       "      <td>343</td>\n",
       "      <td>690</td>\n",
       "      <td>1720</td>\n",
       "      <td>4388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015101520</td>\n",
       "      <td>...</td>\n",
       "      <td>165</td>\n",
       "      <td>861</td>\n",
       "      <td>29</td>\n",
       "      <td>291</td>\n",
       "      <td>438</td>\n",
       "      <td>309</td>\n",
       "      <td>343</td>\n",
       "      <td>1425</td>\n",
       "      <td>51</td>\n",
       "      <td>2591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>2015101217</td>\n",
       "      <td>...</td>\n",
       "      <td>456</td>\n",
       "      <td>45</td>\n",
       "      <td>135</td>\n",
       "      <td>523</td>\n",
       "      <td>455</td>\n",
       "      <td>554</td>\n",
       "      <td>633</td>\n",
       "      <td>1510</td>\n",
       "      <td>1582</td>\n",
       "      <td>3954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              枠番  馬番    斤量    単勝  course_len weather race_type ground_state   \n",
       "201701010101   3   3  54.0   3.0        18.0       晴         芝            良  \\\n",
       "201701010101   5   5  54.0   1.5        18.0       晴         芝            良   \n",
       "201701010101   7   7  54.0   6.2        18.0       晴         芝            良   \n",
       "201701010101   1   1  54.0  31.1        18.0       晴         芝            良   \n",
       "201701010101   2   2  53.0  22.8        18.0       晴         芝            良   \n",
       "\n",
       "                   date    horse_id  ... peds_52  peds_53 peds_54  peds_55   \n",
       "201701010101 2017-07-29  2015100713  ...     194      906     273      508  \\\n",
       "201701010101 2017-07-29  2015103211  ...     285      331      28      305   \n",
       "201701010101 2017-07-29  2015103578  ...      76      612     135      523   \n",
       "201701010101 2017-07-29  2015101520  ...     165      861      29      291   \n",
       "201701010101 2017-07-29  2015101217  ...     456       45     135      523   \n",
       "\n",
       "              peds_56  peds_57  peds_58  peds_59  peds_60  peds_61  \n",
       "201701010101      716     1293      343      430     1003     1290  \n",
       "201701010101      385       96      117     1231      832     3001  \n",
       "201701010101      455      554      343      690     1720     4388  \n",
       "201701010101      438      309      343     1425       51     2591  \n",
       "201701010101      455      554      633     1510     1582     3954  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.merge_peds(p.peds_e)\n",
    "r.data_pe.head() #jupyterで出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.process_categorical() #r.le_horse, r.le_jockeyに対応関係が保存される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#時系列に沿って訓練データとテストデータに分ける関数\n",
    "def split_data(df, test_size=0.3):\n",
    "    sorted_id_list = df.sort_values(\"date\").index.unique()\n",
    "    train_id_list = sorted_id_list[: round(len(sorted_id_list) * (1 - test_size))]\n",
    "    test_id_list = sorted_id_list[round(len(sorted_id_list) * (1 - test_size)) :]\n",
    "    train = df.loc[train_id_list]\n",
    "    test = df.loc[test_id_list]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_data(r.data_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['枠番', '馬番', '斤量', '単勝', 'course_len', 'date', 'horse_id', 'jockey_id', 'rank', '年齢', '体重', '体重変化', 'n_horses', '着順_5R', '賞金_5R', '着差_5R', 'first_corner_5R', 'final_corner_5R', 'first_to_rank_5R', 'first_to_final_5R', 'final_to_rank_5R', '着順_course_len_5R', '賞金_course_len_5R', '着差_course_len_5R', 'first_corner_course_len_5R', 'final_corner_course_len_5R', 'first_to_rank_course_len_5R', 'first_to_final_course_len_5R', 'final_to_rank_course_len_5R', '着順_race_type_5R', '賞金_race_type_5R', '着差_race_type_5R', 'first_corner_race_type_5R', 'final_corner_race_type_5R', 'first_to_rank_race_type_5R', 'first_to_final_race_type_5R', 'final_to_rank_race_type_5R', '着順_開催_5R', '賞金_開催_5R', '着差_開催_5R', 'first_corner_開催_5R', 'final_corner_開催_5R', 'first_to_rank_開催_5R', 'first_to_final_開催_5R', 'final_to_rank_開催_5R', '着順_9R', '賞金_9R', '着差_9R', 'first_corner_9R', 'final_corner_9R', 'first_to_rank_9R', 'first_to_final_9R', 'final_to_rank_9R', '着順_course_len_9R', '賞金_course_len_9R', '着差_course_len_9R', 'first_corner_course_len_9R', 'final_corner_course_len_9R', 'first_to_rank_course_len_9R', 'first_to_final_course_len_9R', 'final_to_rank_course_len_9R', '着順_race_type_9R', '賞金_race_type_9R', '着差_race_type_9R', 'first_corner_race_type_9R', 'final_corner_race_type_9R', 'first_to_rank_race_type_9R', 'first_to_final_race_type_9R', 'final_to_rank_race_type_9R', '着順_開催_9R', '賞金_開催_9R', '着差_開催_9R', 'first_corner_開催_9R', 'final_corner_開催_9R', 'first_to_rank_開催_9R', 'first_to_final_開催_9R', 'final_to_rank_開催_9R', '着順_allR', '賞金_allR', '着差_allR', 'first_corner_allR', 'final_corner_allR', 'first_to_rank_allR', 'first_to_final_allR', 'final_to_rank_allR', '着順_course_len_allR', '賞金_course_len_allR', '着差_course_len_allR', 'first_corner_course_len_allR', 'final_corner_course_len_allR', 'first_to_rank_course_len_allR', 'first_to_final_course_len_allR', 'final_to_rank_course_len_allR', '着順_race_type_allR', '賞金_race_type_allR', '着差_race_type_allR', 'first_corner_race_type_allR', 'final_corner_race_type_allR', 'first_to_rank_race_type_allR', 'first_to_final_race_type_allR', 'final_to_rank_race_type_allR', '着順_開催_allR', '賞金_開催_allR', '着差_開催_allR', 'first_corner_開催_allR', 'final_corner_開催_allR', 'first_to_rank_開催_allR', 'first_to_final_開催_allR', 'final_to_rank_開催_allR', 'interval', 'peds_0', 'peds_1', 'peds_2', 'peds_3', 'peds_4', 'peds_5', 'peds_6', 'peds_7', 'peds_8', 'peds_9', 'peds_10', 'peds_11', 'peds_12', 'peds_13', 'peds_14', 'peds_15', 'peds_16', 'peds_17', 'peds_18', 'peds_19', 'peds_20', 'peds_21', 'peds_22', 'peds_23', 'peds_24', 'peds_25', 'peds_26', 'peds_27', 'peds_28', 'peds_29', 'peds_30', 'peds_31', 'peds_32', 'peds_33', 'peds_34', 'peds_35', 'peds_36', 'peds_37', 'peds_38', 'peds_39', 'peds_40', 'peds_41', 'peds_42', 'peds_43', 'peds_44', 'peds_45', 'peds_46', 'peds_47', 'peds_48', 'peds_49', 'peds_50', 'peds_51', 'peds_52', 'peds_53', 'peds_54', 'peds_55', 'peds_56', 'peds_57', 'peds_58', 'peds_59', 'peds_60', 'peds_61', 'weather_晴', 'weather_曇', 'weather_雨', 'weather_小雨', 'weather_小雪', 'weather_雪', 'race_type_芝', 'race_type_ダート', 'race_type_障害', 'ground_state_良', 'ground_state_稍重', 'ground_state_重', 'ground_state_不良', '性_牝', '性_牡', '性_セ']\n"
     ]
    }
   ],
   "source": [
    "print(list(r.data_c.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = split_data(train)\n",
    "\n",
    "#説明変数と目的変数に分ける。dateはこの後不要なので省く。単勝オッズも学習時には使わない。\n",
    "X_train = train.drop(['rank', 'date', '単勝'], axis=1)\n",
    "y_train = train['rank']\n",
    "X_valid = valid.drop(['rank', 'date', '単勝'], axis=1)\n",
    "y_valid = valid['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-16 21:13:50,312]\u001b[0m A new study created in memory with name: no-name-6d10f714-636f-4194-b1fa-e0905815a1c4\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\kenos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\kenos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.458954:  14%|#4        | 1/7 [00:11<01:09, 11.57s/it]\u001b[32m[I 2023-06-16 21:14:01,901]\u001b[0m Trial 0 finished with value: 0.4589541275278615 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.4589541275278615.\u001b[0m\n",
      "feature_fraction, val_score: 0.458954:  14%|#4        | 1/7 [00:11<01:09, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.429877\tvalid_1's binary_logloss: 0.458954\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.458954:  29%|##8       | 2/7 [00:21<00:52, 10.50s/it]\u001b[32m[I 2023-06-16 21:14:11,657]\u001b[0m Trial 1 finished with value: 0.4590172981746239 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.4589541275278615.\u001b[0m\n",
      "feature_fraction, val_score: 0.458954:  29%|##8       | 2/7 [00:21<00:52, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.426213\tvalid_1's binary_logloss: 0.45905\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.428283\tvalid_1's binary_logloss: 0.459017\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425878\tvalid_1's binary_logloss: 0.458622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.458377:  43%|####2     | 3/7 [00:32<00:42, 10.68s/it]\u001b[32m[I 2023-06-16 21:14:22,554]\u001b[0m Trial 2 finished with value: 0.45837705814437285 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.45837705814437285.\u001b[0m\n",
      "feature_fraction, val_score: 0.458377:  43%|####2     | 3/7 [00:32<00:42, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's binary_logloss: 0.421869\tvalid_1's binary_logloss: 0.458377\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.42761\tvalid_1's binary_logloss: 0.458106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.457693:  57%|#####7    | 4/7 [00:41<00:30, 10.02s/it]\u001b[32m[I 2023-06-16 21:14:31,566]\u001b[0m Trial 3 finished with value: 0.4576925443720778 and parameters: {'feature_fraction': 0.4}. Best is trial 3 with value: 0.4576925443720778.\u001b[0m\n",
      "feature_fraction, val_score: 0.457693:  57%|#####7    | 4/7 [00:41<00:30, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.421155\tvalid_1's binary_logloss: 0.457693\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.457693:  71%|#######1  | 5/7 [00:50<00:19,  9.89s/it]\u001b[32m[I 2023-06-16 21:14:41,224]\u001b[0m Trial 4 finished with value: 0.4585877919892416 and parameters: {'feature_fraction': 0.6}. Best is trial 3 with value: 0.4576925443720778.\u001b[0m\n",
      "feature_fraction, val_score: 0.457693:  71%|#######1  | 5/7 [00:50<00:19,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.426761\tvalid_1's binary_logloss: 0.458621\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.429247\tvalid_1's binary_logloss: 0.458588\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.426989\tvalid_1's binary_logloss: 0.458641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.457693:  86%|########5 | 6/7 [01:01<00:10, 10.15s/it]\u001b[32m[I 2023-06-16 21:14:51,882]\u001b[0m Trial 5 finished with value: 0.4584926733800296 and parameters: {'feature_fraction': 0.5}. Best is trial 3 with value: 0.4576925443720778.\u001b[0m\n",
      "feature_fraction, val_score: 0.457693:  86%|########5 | 6/7 [01:01<00:10, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.421651\tvalid_1's binary_logloss: 0.458493\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425286\tvalid_1's binary_logloss: 0.458539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.457693: 100%|##########| 7/7 [01:12<00:00, 10.55s/it]\u001b[32m[I 2023-06-16 21:15:03,266]\u001b[0m Trial 6 finished with value: 0.458539349234576 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.4576925443720778.\u001b[0m\n",
      "feature_fraction, val_score: 0.457693: 100%|##########| 7/7 [01:12<00:00, 10.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.425286\tvalid_1's binary_logloss: 0.458539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457693:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457693:   5%|5         | 1/20 [00:09<03:03,  9.67s/it]\u001b[32m[I 2023-06-16 21:15:12,973]\u001b[0m Trial 7 finished with value: 0.4599144273855329 and parameters: {'num_leaves': 140}. Best is trial 7 with value: 0.4599144273855329.\u001b[0m\n",
      "num_leaves, val_score: 0.457693:   5%|5         | 1/20 [00:09<03:03,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.395498\tvalid_1's binary_logloss: 0.459914\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457693:  10%|#         | 2/20 [00:19<02:53,  9.62s/it]\u001b[32m[I 2023-06-16 21:15:22,557]\u001b[0m Trial 8 finished with value: 0.4585164727400624 and parameters: {'num_leaves': 72}. Best is trial 8 with value: 0.4585164727400624.\u001b[0m\n",
      "num_leaves, val_score: 0.457693:  10%|#         | 2/20 [00:19<02:53,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's binary_logloss: 0.405391\tvalid_1's binary_logloss: 0.458516\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457693:  15%|#5        | 3/20 [00:29<02:50, 10.05s/it]\u001b[32m[I 2023-06-16 21:15:33,104]\u001b[0m Trial 9 finished with value: 0.45913518773477074 and parameters: {'num_leaves': 110}. Best is trial 8 with value: 0.4585164727400624.\u001b[0m\n",
      "num_leaves, val_score: 0.457693:  15%|#5        | 3/20 [00:29<02:50, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's binary_logloss: 0.385587\tvalid_1's binary_logloss: 0.459135\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457693:  20%|##        | 4/20 [00:41<02:50, 10.64s/it]\u001b[32m[I 2023-06-16 21:15:44,642]\u001b[0m Trial 10 finished with value: 0.46179906327548953 and parameters: {'num_leaves': 217}. Best is trial 8 with value: 0.4585164727400624.\u001b[0m\n",
      "num_leaves, val_score: 0.457693:  20%|##        | 4/20 [00:41<02:50, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.352871\tvalid_1's binary_logloss: 0.461799\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.462357\tvalid_1's binary_logloss: 0.470007\n",
      "[200]\tvalid_0's binary_logloss: 0.457263\tvalid_1's binary_logloss: 0.466046\n",
      "[300]\tvalid_0's binary_logloss: 0.454291\tvalid_1's binary_logloss: 0.464253\n",
      "[400]\tvalid_0's binary_logloss: 0.451814\tvalid_1's binary_logloss: 0.462785\n",
      "[500]\tvalid_0's binary_logloss: 0.449895\tvalid_1's binary_logloss: 0.46187\n",
      "[600]\tvalid_0's binary_logloss: 0.448224\tvalid_1's binary_logloss: 0.46114\n",
      "[700]\tvalid_0's binary_logloss: 0.44671\tvalid_1's binary_logloss: 0.460502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457693:  25%|##5       | 5/20 [00:55<03:00, 12.03s/it]\u001b[32m[I 2023-06-16 21:15:59,132]\u001b[0m Trial 11 finished with value: 0.4600577671377222 and parameters: {'num_leaves': 3}. Best is trial 8 with value: 0.4585164727400624.\u001b[0m\n",
      "num_leaves, val_score: 0.457693:  25%|##5       | 5/20 [00:55<03:00, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[763]\tvalid_0's binary_logloss: 0.445734\tvalid_1's binary_logloss: 0.460058\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425902\tvalid_1's binary_logloss: 0.457852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  30%|###       | 6/20 [01:05<02:36, 11.18s/it]\u001b[32m[I 2023-06-16 21:16:08,682]\u001b[0m Trial 12 finished with value: 0.4575955806949461 and parameters: {'num_leaves': 33}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  30%|###       | 6/20 [01:05<02:36, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's binary_logloss: 0.419659\tvalid_1's binary_logloss: 0.457596\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  35%|###5      | 7/20 [01:16<02:24, 11.12s/it]\u001b[32m[I 2023-06-16 21:16:19,661]\u001b[0m Trial 13 finished with value: 0.4601438664506896 and parameters: {'num_leaves': 173}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  35%|###5      | 7/20 [01:16<02:24, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's binary_logloss: 0.365049\tvalid_1's binary_logloss: 0.460144\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  40%|####      | 8/20 [01:26<02:10, 10.89s/it]\u001b[32m[I 2023-06-16 21:16:30,052]\u001b[0m Trial 14 finished with value: 0.46149494536877006 and parameters: {'num_leaves': 212}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  40%|####      | 8/20 [01:26<02:10, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's binary_logloss: 0.366881\tvalid_1's binary_logloss: 0.461495\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  45%|####5     | 9/20 [01:36<01:54, 10.38s/it]\u001b[32m[I 2023-06-16 21:16:39,323]\u001b[0m Trial 15 finished with value: 0.4585660169279525 and parameters: {'num_leaves': 36}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  45%|####5     | 9/20 [01:36<01:54, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's binary_logloss: 0.427491\tvalid_1's binary_logloss: 0.458566\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  50%|#####     | 10/20 [01:46<01:45, 10.51s/it]\u001b[32m[I 2023-06-16 21:16:50,110]\u001b[0m Trial 16 finished with value: 0.46008439717671856 and parameters: {'num_leaves': 148}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  50%|#####     | 10/20 [01:46<01:45, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's binary_logloss: 0.373125\tvalid_1's binary_logloss: 0.460084\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.39902\tvalid_1's binary_logloss: 0.458601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  55%|#####5    | 11/20 [01:56<01:33, 10.37s/it]\u001b[32m[I 2023-06-16 21:17:00,174]\u001b[0m Trial 17 finished with value: 0.45855884159368004 and parameters: {'num_leaves': 68}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  55%|#####5    | 11/20 [01:56<01:33, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.399499\tvalid_1's binary_logloss: 0.458559\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  60%|######    | 12/20 [02:06<01:20, 10.10s/it]\u001b[32m[I 2023-06-16 21:17:09,666]\u001b[0m Trial 18 finished with value: 0.4586794115388186 and parameters: {'num_leaves': 77}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  60%|######    | 12/20 [02:06<01:20, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's binary_logloss: 0.40626\tvalid_1's binary_logloss: 0.458679\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.467142\tvalid_1's binary_logloss: 0.474037\n",
      "[200]\tvalid_0's binary_logloss: 0.463187\tvalid_1's binary_logloss: 0.470723\n",
      "[300]\tvalid_0's binary_logloss: 0.460947\tvalid_1's binary_logloss: 0.468932\n",
      "[400]\tvalid_0's binary_logloss: 0.459439\tvalid_1's binary_logloss: 0.467787\n",
      "[500]\tvalid_0's binary_logloss: 0.458326\tvalid_1's binary_logloss: 0.467064\n",
      "[600]\tvalid_0's binary_logloss: 0.457458\tvalid_1's binary_logloss: 0.466438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  65%|######5   | 13/20 [02:18<01:13, 10.57s/it]\u001b[32m[I 2023-06-16 21:17:21,296]\u001b[0m Trial 19 finished with value: 0.46601682490064955 and parameters: {'num_leaves': 2}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  65%|######5   | 13/20 [02:18<01:13, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[681]\tvalid_0's binary_logloss: 0.456872\tvalid_1's binary_logloss: 0.466017\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.39902\tvalid_1's binary_logloss: 0.458601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  70%|#######   | 14/20 [02:27<01:02, 10.38s/it]\u001b[32m[I 2023-06-16 21:17:31,248]\u001b[0m Trial 20 finished with value: 0.45855884159368004 and parameters: {'num_leaves': 68}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  70%|#######   | 14/20 [02:27<01:02, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.399499\tvalid_1's binary_logloss: 0.458559\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  75%|#######5  | 15/20 [02:37<00:51, 10.27s/it]\u001b[32m[I 2023-06-16 21:17:41,279]\u001b[0m Trial 21 finished with value: 0.45909827120436686 and parameters: {'num_leaves': 102}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  75%|#######5  | 15/20 [02:38<00:51, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's binary_logloss: 0.391995\tvalid_1's binary_logloss: 0.459098\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.421958\tvalid_1's binary_logloss: 0.457871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  80%|########  | 16/20 [02:47<00:39,  9.99s/it]\u001b[32m[I 2023-06-16 21:17:50,605]\u001b[0m Trial 22 finished with value: 0.45762608106512864 and parameters: {'num_leaves': 38}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  80%|########  | 16/20 [02:47<00:39,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's binary_logloss: 0.417906\tvalid_1's binary_logloss: 0.457626\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428257\tvalid_1's binary_logloss: 0.457767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  85%|########5 | 17/20 [02:56<00:29,  9.80s/it]\u001b[32m[I 2023-06-16 21:17:59,965]\u001b[0m Trial 23 finished with value: 0.45765662929498974 and parameters: {'num_leaves': 30}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  85%|########5 | 17/20 [02:56<00:29,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.425802\tvalid_1's binary_logloss: 0.457657\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425902\tvalid_1's binary_logloss: 0.457852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  90%|######### | 18/20 [03:06<00:19,  9.79s/it]\u001b[32m[I 2023-06-16 21:18:09,731]\u001b[0m Trial 24 finished with value: 0.4575955806949461 and parameters: {'num_leaves': 33}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  90%|######### | 18/20 [03:06<00:19,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's binary_logloss: 0.419659\tvalid_1's binary_logloss: 0.457596\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596:  95%|#########5| 19/20 [03:16<00:09,  9.88s/it]\u001b[32m[I 2023-06-16 21:18:19,815]\u001b[0m Trial 25 finished with value: 0.46043019605780844 and parameters: {'num_leaves': 177}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596:  95%|#########5| 19/20 [03:16<00:09,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's binary_logloss: 0.376181\tvalid_1's binary_logloss: 0.46043\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457596: 100%|##########| 20/20 [03:25<00:00,  9.73s/it]\u001b[32m[I 2023-06-16 21:18:29,205]\u001b[0m Trial 26 finished with value: 0.4582499348456999 and parameters: {'num_leaves': 45}. Best is trial 12 with value: 0.4575955806949461.\u001b[0m\n",
      "num_leaves, val_score: 0.457596: 100%|##########| 20/20 [03:25<00:00, 10.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.416287\tvalid_1's binary_logloss: 0.458329\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's binary_logloss: 0.418\tvalid_1's binary_logloss: 0.45825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425642\tvalid_1's binary_logloss: 0.45891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596:  10%|#         | 1/10 [00:09<01:26,  9.58s/it]\u001b[32m[I 2023-06-16 21:18:38,815]\u001b[0m Trial 27 finished with value: 0.45837086303089986 and parameters: {'bagging_fraction': 0.7260429650751228, 'bagging_freq': 2}. Best is trial 27 with value: 0.45837086303089986.\u001b[0m\n",
      "bagging, val_score: 0.457596:  10%|#         | 1/10 [00:09<01:26,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's binary_logloss: 0.417894\tvalid_1's binary_logloss: 0.458371\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425772\tvalid_1's binary_logloss: 0.459469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596:  20%|##        | 2/10 [00:18<01:11,  8.98s/it]\u001b[32m[I 2023-06-16 21:18:47,374]\u001b[0m Trial 28 finished with value: 0.45927097596025246 and parameters: {'bagging_fraction': 0.6547105544499044, 'bagging_freq': 6}. Best is trial 27 with value: 0.45837086303089986.\u001b[0m\n",
      "bagging, val_score: 0.457596:  20%|##        | 2/10 [00:18<01:11,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's binary_logloss: 0.423314\tvalid_1's binary_logloss: 0.459271\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596:  30%|###       | 3/10 [00:25<00:57,  8.28s/it]\u001b[32m[I 2023-06-16 21:18:54,819]\u001b[0m Trial 29 finished with value: 0.462087635108612 and parameters: {'bagging_fraction': 0.4028313137145883, 'bagging_freq': 1}. Best is trial 27 with value: 0.45837086303089986.\u001b[0m\n",
      "bagging, val_score: 0.457596:  30%|###       | 3/10 [00:25<00:57,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's binary_logloss: 0.434405\tvalid_1's binary_logloss: 0.462088\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.426084\tvalid_1's binary_logloss: 0.458724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596:  40%|####      | 4/10 [00:34<00:52,  8.71s/it]\u001b[32m[I 2023-06-16 21:19:04,183]\u001b[0m Trial 30 finished with value: 0.4584386289675136 and parameters: {'bagging_fraction': 0.802449450836738, 'bagging_freq': 6}. Best is trial 27 with value: 0.45837086303089986.\u001b[0m\n",
      "bagging, val_score: 0.457596:  40%|####      | 4/10 [00:34<00:52,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.423242\tvalid_1's binary_logloss: 0.458439\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.42683\tvalid_1's binary_logloss: 0.460369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596:  50%|#####     | 5/10 [00:43<00:43,  8.73s/it]\u001b[32m[I 2023-06-16 21:19:12,959]\u001b[0m Trial 31 finished with value: 0.4601910265662322 and parameters: {'bagging_fraction': 0.4820239538111085, 'bagging_freq': 5}. Best is trial 27 with value: 0.45837086303089986.\u001b[0m\n",
      "bagging, val_score: 0.457596:  50%|#####     | 5/10 [00:43<00:43,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's binary_logloss: 0.424915\tvalid_1's binary_logloss: 0.460191\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.42561\tvalid_1's binary_logloss: 0.458075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596:  60%|######    | 6/10 [00:53<00:35,  8.97s/it]\u001b[32m[I 2023-06-16 21:19:22,398]\u001b[0m Trial 32 finished with value: 0.45768536981918356 and parameters: {'bagging_fraction': 0.9347931725882498, 'bagging_freq': 2}. Best is trial 32 with value: 0.45768536981918356.\u001b[0m\n",
      "bagging, val_score: 0.457596:  60%|######    | 6/10 [00:53<00:35,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.42275\tvalid_1's binary_logloss: 0.457685\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596:  70%|#######   | 7/10 [01:01<00:26,  8.72s/it]\u001b[32m[I 2023-06-16 21:19:30,586]\u001b[0m Trial 33 finished with value: 0.4601640585376917 and parameters: {'bagging_fraction': 0.5111969317302304, 'bagging_freq': 1}. Best is trial 32 with value: 0.45768536981918356.\u001b[0m\n",
      "bagging, val_score: 0.457596:  70%|#######   | 7/10 [01:01<00:26,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's binary_logloss: 0.432699\tvalid_1's binary_logloss: 0.460164\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596:  80%|########  | 8/10 [01:09<00:17,  8.67s/it]\u001b[32m[I 2023-06-16 21:19:39,164]\u001b[0m Trial 34 finished with value: 0.4606432271156078 and parameters: {'bagging_fraction': 0.531818495575215, 'bagging_freq': 7}. Best is trial 32 with value: 0.45768536981918356.\u001b[0m\n",
      "bagging, val_score: 0.457596:  80%|########  | 8/10 [01:09<00:17,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.426458\tvalid_1's binary_logloss: 0.460729\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.429229\tvalid_1's binary_logloss: 0.460643\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425979\tvalid_1's binary_logloss: 0.458639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596:  90%|######### | 9/10 [01:19<00:08,  8.89s/it]\u001b[32m[I 2023-06-16 21:19:48,535]\u001b[0m Trial 35 finished with value: 0.45805012402168344 and parameters: {'bagging_fraction': 0.8870098894544057, 'bagging_freq': 2}. Best is trial 32 with value: 0.45768536981918356.\u001b[0m\n",
      "bagging, val_score: 0.457596:  90%|######### | 9/10 [01:19<00:08,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.423046\tvalid_1's binary_logloss: 0.45805\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425918\tvalid_1's binary_logloss: 0.458405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457596: 100%|##########| 10/10 [01:28<00:00,  9.04s/it]\u001b[32m[I 2023-06-16 21:19:57,907]\u001b[0m Trial 36 finished with value: 0.4583661514224208 and parameters: {'bagging_fraction': 0.8897348492363203, 'bagging_freq': 2}. Best is trial 32 with value: 0.45768536981918356.\u001b[0m\n",
      "bagging, val_score: 0.457596: 100%|##########| 10/10 [01:28<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.425609\tvalid_1's binary_logloss: 0.458366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.457596:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425707\tvalid_1's binary_logloss: 0.457974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.457377:  33%|###3      | 1/3 [00:09<00:19,  9.71s/it]\u001b[32m[I 2023-06-16 21:20:07,642]\u001b[0m Trial 37 finished with value: 0.4573770317493555 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.4573770317493555.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.457377:  33%|###3      | 1/3 [00:09<00:19,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.41849\tvalid_1's binary_logloss: 0.457377\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.143390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425395\tvalid_1's binary_logloss: 0.457707\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.424579\tvalid_1's binary_logloss: 0.457704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.457377:  67%|######6   | 2/3 [00:18<00:08,  8.90s/it]\u001b[32m[I 2023-06-16 21:20:15,979]\u001b[0m Trial 38 finished with value: 0.4577042071568392 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.4573770317493555.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.457377:  67%|######6   | 2/3 [00:18<00:08,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.457377: 100%|##########| 3/3 [00:25<00:00,  8.28s/it]\u001b[32m[I 2023-06-16 21:20:23,509]\u001b[0m Trial 39 finished with value: 0.45815976252175 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.4573770317493555.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.457377: 100%|##########| 3/3 [00:25<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's binary_logloss: 0.430033\tvalid_1's binary_logloss: 0.45816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457377:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425765\tvalid_1's binary_logloss: 0.458042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457309:   5%|5         | 1/20 [00:08<02:46,  8.79s/it]\u001b[32m[I 2023-06-16 21:20:32,324]\u001b[0m Trial 40 finished with value: 0.4573093799131221 and parameters: {'lambda_l1': 0.0007773998922821829, 'lambda_l2': 3.2012859298995277e-06}. Best is trial 40 with value: 0.4573093799131221.\u001b[0m\n",
      "regularization_factors, val_score: 0.457309:   5%|5         | 1/20 [00:08<02:46,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's binary_logloss: 0.414766\tvalid_1's binary_logloss: 0.457309\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.426427\tvalid_1's binary_logloss: 0.45734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457106:  10%|#         | 2/20 [00:17<02:35,  8.62s/it]\u001b[32m[I 2023-06-16 21:20:40,818]\u001b[0m Trial 41 finished with value: 0.45710606817445343 and parameters: {'lambda_l1': 6.616957066014342e-05, 'lambda_l2': 0.400853048601546}. Best is trial 41 with value: 0.45710606817445343.\u001b[0m\n",
      "regularization_factors, val_score: 0.457106:  10%|#         | 2/20 [00:17<02:35,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's binary_logloss: 0.421559\tvalid_1's binary_logloss: 0.457106\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425707\tvalid_1's binary_logloss: 0.457974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457106:  15%|#5        | 3/20 [00:25<02:22,  8.40s/it]\u001b[32m[I 2023-06-16 21:20:48,951]\u001b[0m Trial 42 finished with value: 0.4573770550368445 and parameters: {'lambda_l1': 1.1027313099672533e-08, 'lambda_l2': 1.242001404761155e-07}. Best is trial 41 with value: 0.45710606817445343.\u001b[0m\n",
      "regularization_factors, val_score: 0.457106:  15%|#5        | 3/20 [00:25<02:22,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.41849\tvalid_1's binary_logloss: 0.457377\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.426174\tvalid_1's binary_logloss: 0.457945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457106:  20%|##        | 4/20 [00:34<02:16,  8.54s/it]\u001b[32m[I 2023-06-16 21:20:57,717]\u001b[0m Trial 43 finished with value: 0.4577240336423796 and parameters: {'lambda_l1': 0.010882827930218712, 'lambda_l2': 0.2708162972907513}. Best is trial 41 with value: 0.45710606817445343.\u001b[0m\n",
      "regularization_factors, val_score: 0.457106:  20%|##        | 4/20 [00:34<02:16,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's binary_logloss: 0.423073\tvalid_1's binary_logloss: 0.457724\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457106:  25%|##5       | 5/20 [00:41<02:02,  8.19s/it]\u001b[32m[I 2023-06-16 21:21:05,281]\u001b[0m Trial 44 finished with value: 0.4582431359878819 and parameters: {'lambda_l1': 1.6996492507894156e-07, 'lambda_l2': 0.0014991323116035308}. Best is trial 41 with value: 0.45710606817445343.\u001b[0m\n",
      "regularization_factors, val_score: 0.457106:  25%|##5       | 5/20 [00:41<02:02,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's binary_logloss: 0.432197\tvalid_1's binary_logloss: 0.458243\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.426341\tvalid_1's binary_logloss: 0.457181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456989:  30%|###       | 6/20 [00:50<01:57,  8.36s/it]\u001b[32m[I 2023-06-16 21:21:13,980]\u001b[0m Trial 45 finished with value: 0.4569889597973449 and parameters: {'lambda_l1': 1.0517138394360073, 'lambda_l2': 7.635176818135586e-07}. Best is trial 45 with value: 0.4569889597973449.\u001b[0m\n",
      "regularization_factors, val_score: 0.456989:  30%|###       | 6/20 [00:50<01:57,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's binary_logloss: 0.42274\tvalid_1's binary_logloss: 0.456989\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425707\tvalid_1's binary_logloss: 0.457973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456989:  35%|###5      | 7/20 [00:59<01:50,  8.47s/it]\u001b[32m[I 2023-06-16 21:21:22,680]\u001b[0m Trial 46 finished with value: 0.4573784540545382 and parameters: {'lambda_l1': 4.655367559816141e-07, 'lambda_l2': 9.449134137745608e-08}. Best is trial 45 with value: 0.4569889597973449.\u001b[0m\n",
      "regularization_factors, val_score: 0.456989:  35%|###5      | 7/20 [00:59<01:50,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.41849\tvalid_1's binary_logloss: 0.457378\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428023\tvalid_1's binary_logloss: 0.457579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456982:  40%|####      | 8/20 [01:07<01:43,  8.59s/it]\u001b[32m[I 2023-06-16 21:21:31,525]\u001b[0m Trial 47 finished with value: 0.45698150883851635 and parameters: {'lambda_l1': 9.490245203532942e-07, 'lambda_l2': 6.421168438428032}. Best is trial 47 with value: 0.45698150883851635.\u001b[0m\n",
      "regularization_factors, val_score: 0.456982:  40%|####      | 8/20 [01:08<01:43,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.422087\tvalid_1's binary_logloss: 0.456982\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.42626\tvalid_1's binary_logloss: 0.458187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456982:  45%|####5     | 9/20 [01:16<01:33,  8.49s/it]\u001b[32m[I 2023-06-16 21:21:39,784]\u001b[0m Trial 48 finished with value: 0.45768057293913356 and parameters: {'lambda_l1': 0.2019055894080857, 'lambda_l2': 3.5275169933928286e-07}. Best is trial 47 with value: 0.45698150883851635.\u001b[0m\n",
      "regularization_factors, val_score: 0.456982:  45%|####5     | 9/20 [01:16<01:33,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's binary_logloss: 0.418803\tvalid_1's binary_logloss: 0.457681\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.426003\tvalid_1's binary_logloss: 0.458173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456982:  50%|#####     | 10/20 [01:24<01:25,  8.54s/it]\u001b[32m[I 2023-06-16 21:21:48,427]\u001b[0m Trial 49 finished with value: 0.45777922863647086 and parameters: {'lambda_l1': 0.22183125618514202, 'lambda_l2': 2.9286247167445133e-06}. Best is trial 47 with value: 0.45698150883851635.\u001b[0m\n",
      "regularization_factors, val_score: 0.456982:  50%|#####     | 10/20 [01:24<01:25,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.416569\tvalid_1's binary_logloss: 0.457779\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428578\tvalid_1's binary_logloss: 0.457559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456982:  55%|#####5    | 11/20 [01:33<01:18,  8.68s/it]\u001b[32m[I 2023-06-16 21:21:57,441]\u001b[0m Trial 50 finished with value: 0.457220615409413 and parameters: {'lambda_l1': 3.0057843641607915e-05, 'lambda_l2': 8.38297710342227}. Best is trial 47 with value: 0.45698150883851635.\u001b[0m\n",
      "regularization_factors, val_score: 0.456982:  55%|#####5    | 11/20 [01:33<01:18,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.424051\tvalid_1's binary_logloss: 0.457221\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.430216\tvalid_1's binary_logloss: 0.457314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456655:  60%|######    | 12/20 [01:43<01:11,  8.90s/it]\u001b[32m[I 2023-06-16 21:22:06,843]\u001b[0m Trial 51 finished with value: 0.45665487605444693 and parameters: {'lambda_l1': 9.113641784001668, 'lambda_l2': 7.523632870105917e-05}. Best is trial 51 with value: 0.45665487605444693.\u001b[0m\n",
      "regularization_factors, val_score: 0.456655:  60%|######    | 12/20 [01:43<01:11,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's binary_logloss: 0.419499\tvalid_1's binary_logloss: 0.456655\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428073\tvalid_1's binary_logloss: 0.457375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456536:  65%|######5   | 13/20 [01:52<01:03,  9.00s/it]\u001b[32m[I 2023-06-16 21:22:16,077]\u001b[0m Trial 52 finished with value: 0.4565360225003592 and parameters: {'lambda_l1': 3.649389294042618, 'lambda_l2': 0.00012558479384857605}. Best is trial 52 with value: 0.4565360225003592.\u001b[0m\n",
      "regularization_factors, val_score: 0.456536:  65%|######5   | 13/20 [01:52<01:03,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's binary_logloss: 0.415102\tvalid_1's binary_logloss: 0.456536\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.427325\tvalid_1's binary_logloss: 0.457134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456536:  70%|#######   | 14/20 [02:01<00:53,  8.97s/it]\u001b[32m[I 2023-06-16 21:22:24,958]\u001b[0m Trial 53 finished with value: 0.45669038044641436 and parameters: {'lambda_l1': 2.2484581452667936, 'lambda_l2': 0.0002539292304807585}. Best is trial 52 with value: 0.4565360225003592.\u001b[0m\n",
      "regularization_factors, val_score: 0.456536:  70%|#######   | 14/20 [02:01<00:53,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's binary_logloss: 0.419333\tvalid_1's binary_logloss: 0.45669\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.429253\tvalid_1's binary_logloss: 0.457541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456536:  75%|#######5  | 15/20 [02:10<00:45,  9.07s/it]\u001b[32m[I 2023-06-16 21:22:34,304]\u001b[0m Trial 54 finished with value: 0.4569392392015818 and parameters: {'lambda_l1': 5.673852371775013, 'lambda_l2': 7.767625929948251e-05}. Best is trial 52 with value: 0.4565360225003592.\u001b[0m\n",
      "regularization_factors, val_score: 0.456536:  75%|#######5  | 15/20 [02:10<00:45,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's binary_logloss: 0.420011\tvalid_1's binary_logloss: 0.456939\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.428943\tvalid_1's binary_logloss: 0.45717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456536:  80%|########  | 16/20 [02:19<00:35,  8.91s/it]\u001b[32m[I 2023-06-16 21:22:42,816]\u001b[0m Trial 55 finished with value: 0.4566797588091834 and parameters: {'lambda_l1': 5.018847808162718, 'lambda_l2': 1.220872659800592e-08}. Best is trial 52 with value: 0.4565360225003592.\u001b[0m\n",
      "regularization_factors, val_score: 0.456536:  80%|########  | 16/20 [02:19<00:35,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.424343\tvalid_1's binary_logloss: 0.45668\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.456536:  85%|########5 | 17/20 [02:27<00:25,  8.62s/it]\u001b[32m[I 2023-06-16 21:22:50,743]\u001b[0m Trial 56 finished with value: 0.45787284114078697 and parameters: {'lambda_l1': 0.032488863187699966, 'lambda_l2': 3.4829067233683635e-05}. Best is trial 52 with value: 0.4565360225003592.\u001b[0m\n",
      "regularization_factors, val_score: 0.456536:  85%|########5 | 17/20 [02:27<00:25,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.425791\tvalid_1's binary_logloss: 0.457926\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.427815\tvalid_1's binary_logloss: 0.457873\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.430241\tvalid_1's binary_logloss: 0.457011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.455679:  90%|######### | 18/20 [02:36<00:17,  8.94s/it]\u001b[32m[I 2023-06-16 21:23:00,452]\u001b[0m Trial 57 finished with value: 0.4556789783497547 and parameters: {'lambda_l1': 8.955559716312521, 'lambda_l2': 0.002306507164824572}. Best is trial 57 with value: 0.4556789783497547.\u001b[0m\n",
      "regularization_factors, val_score: 0.455679:  90%|######### | 18/20 [02:36<00:17,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's binary_logloss: 0.417397\tvalid_1's binary_logloss: 0.455679\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.455679:  95%|#########5| 19/20 [02:44<00:08,  8.68s/it]\u001b[32m[I 2023-06-16 21:23:08,524]\u001b[0m Trial 58 finished with value: 0.45811644266226587 and parameters: {'lambda_l1': 0.38822388291282683, 'lambda_l2': 0.0025617784247268655}. Best is trial 57 with value: 0.4556789783497547.\u001b[0m\n",
      "regularization_factors, val_score: 0.455679:  95%|#########5| 19/20 [02:45<00:08,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.426275\tvalid_1's binary_logloss: 0.458125\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.428295\tvalid_1's binary_logloss: 0.458116\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.425646\tvalid_1's binary_logloss: 0.457971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.455679: 100%|##########| 20/20 [02:53<00:00,  8.65s/it]\u001b[32m[I 2023-06-16 21:23:17,096]\u001b[0m Trial 59 finished with value: 0.4573904030837565 and parameters: {'lambda_l1': 0.025948843511080254, 'lambda_l2': 0.005152339738372678}. Best is trial 57 with value: 0.4556789783497547.\u001b[0m\n",
      "regularization_factors, val_score: 0.455679: 100%|##########| 20/20 [02:53<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's binary_logloss: 0.419513\tvalid_1's binary_logloss: 0.45739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455679:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.4303\tvalid_1's binary_logloss: 0.457113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455679:  20%|##        | 1/5 [00:08<00:33,  8.45s/it]\u001b[32m[I 2023-06-16 21:23:25,570]\u001b[0m Trial 60 finished with value: 0.45635055704496147 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.45635055704496147.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.455679:  20%|##        | 1/5 [00:08<00:33,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's binary_logloss: 0.424337\tvalid_1's binary_logloss: 0.456351\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.430347\tvalid_1's binary_logloss: 0.457008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455679:  40%|####      | 2/5 [00:17<00:25,  8.60s/it]\u001b[32m[I 2023-06-16 21:23:34,284]\u001b[0m Trial 61 finished with value: 0.45650412105773047 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.45635055704496147.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.455679:  40%|####      | 2/5 [00:17<00:25,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.426004\tvalid_1's binary_logloss: 0.456504\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.43018\tvalid_1's binary_logloss: 0.457195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455679:  60%|######    | 3/5 [00:26<00:18,  9.04s/it]\u001b[32m[I 2023-06-16 21:23:43,844]\u001b[0m Trial 62 finished with value: 0.45625641826781316 and parameters: {'min_child_samples': 5}. Best is trial 62 with value: 0.45625641826781316.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.455679:  60%|######    | 3/5 [00:26<00:18,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.419743\tvalid_1's binary_logloss: 0.456256\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.430328\tvalid_1's binary_logloss: 0.457052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455679:  80%|########  | 4/5 [00:35<00:09,  9.01s/it]\u001b[32m[I 2023-06-16 21:23:52,810]\u001b[0m Trial 63 finished with value: 0.45612170218943626 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.45612170218943626.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.455679:  80%|########  | 4/5 [00:35<00:09,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.41993\tvalid_1's binary_logloss: 0.456122\n",
      "[LightGBM] [Info] Number of positive: 28756, number of negative: 104111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34110\n",
      "[LightGBM] [Info] Number of data points in the train set: 132867, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216427 -> initscore=-1.286611\n",
      "[LightGBM] [Info] Start training from score -1.286611\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.43018\tvalid_1's binary_logloss: 0.457195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455679: 100%|##########| 5/5 [00:44<00:00,  9.10s/it]\u001b[32m[I 2023-06-16 21:24:02,066]\u001b[0m Trial 64 finished with value: 0.45632970732309136 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.45612170218943626.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.455679: 100%|##########| 5/5 [00:44<00:00,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's binary_logloss: 0.420518\tvalid_1's binary_logloss: 0.45633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#データセットを作成\n",
    "lgb_train = lgb_o.Dataset(X_train.values, y_train.values)\n",
    "lgb_valid = lgb_o.Dataset(X_valid.values, y_valid.values)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary', #今回は0or1の二値予測なのでbinaryを指定\n",
    "    'random_state': 100\n",
    "}\n",
    "\n",
    "#チューニング実行\n",
    "lgb_clf_o = lgb_o.train(params, lgb_train,\n",
    "                        valid_sets=(lgb_train, lgb_valid),\n",
    "                        verbose_eval=100,\n",
    "                        early_stopping_rounds=10,\n",
    "                        optuna_seed=100 #optunaのseed固定\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'random_state': 100,\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 8.955559716312521,\n",
       " 'lambda_l2': 0.002306507164824572,\n",
       " 'num_leaves': 33,\n",
       " 'feature_fraction': 0.41600000000000004,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 0,\n",
       " 'min_child_samples': 20,\n",
       " 'num_iterations': 1000,\n",
       " 'early_stopping_round': 10}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf_o.params #jupyterで出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\kenos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.41600000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41600000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.955559716312521, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.955559716312521\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.002306507164824572, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002306507164824572\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[1]\tvalid_0's binary_logloss: 0.527706\n",
      "[2]\tvalid_0's binary_logloss: 0.529155\n",
      "[3]\tvalid_0's binary_logloss: 0.530083\n",
      "[4]\tvalid_0's binary_logloss: 0.53159\n",
      "[5]\tvalid_0's binary_logloss: 0.530871\n",
      "[6]\tvalid_0's binary_logloss: 0.532077\n",
      "[7]\tvalid_0's binary_logloss: 0.533025\n",
      "[8]\tvalid_0's binary_logloss: 0.535892\n",
      "[9]\tvalid_0's binary_logloss: 0.538047\n",
      "[10]\tvalid_0's binary_logloss: 0.541285\n",
      "[11]\tvalid_0's binary_logloss: 0.54535\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, early_stopping_round=10,\n",
       "               feature_fraction=0.41600000000000004, feature_pre_filter=False,\n",
       "               lambda_l1=8.955559716312521, lambda_l2=0.002306507164824572,\n",
       "               num_iterations=1000, num_leaves=33, objective=&#x27;binary&#x27;,\n",
       "               random_state=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, early_stopping_round=10,\n",
       "               feature_fraction=0.41600000000000004, feature_pre_filter=False,\n",
       "               lambda_l1=8.955559716312521, lambda_l2=0.002306507164824572,\n",
       "               num_iterations=1000, num_leaves=33, objective=&#x27;binary&#x27;,\n",
       "               random_state=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, early_stopping_round=10,\n",
       "               feature_fraction=0.41600000000000004, feature_pre_filter=False,\n",
       "               lambda_l1=8.955559716312521, lambda_l2=0.002306507164824572,\n",
       "               num_iterations=1000, num_leaves=33, objective='binary',\n",
       "               random_state=100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = split_data(r.data_c)\n",
    "\n",
    "#説明変数と目的変数に分ける。dateはこの後不要なので省く。\n",
    "X_train = train.drop(['rank', 'date', '単勝'], axis=1)\n",
    "y_train = train['rank']\n",
    "#2021/3/12追加： テストデータの単勝オッズはシミュレーション時に使用するので残しておく\n",
    "X_test = test.drop(['rank', 'date'], axis=1)\n",
    "y_test = test['rank']\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(**lgb_clf_o.params)\n",
    "lgb_clf.fit(X_train.values, y_train.values, eval_set=[(X_test.values, y_test.values)], early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Return:\n",
    "    def __init__(self, return_tables):\n",
    "        self.return_tables = return_tables\n",
    "    \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.read_pickle(path_list[0])\n",
    "        for path in path_list[1:]:\n",
    "            df = update_data(df, pd.read_pickle(path))\n",
    "        return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(race_id_list):\n",
    "        return_tables = {}\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "\n",
    "                #普通にスクレイピングすると複勝やワイドなどが区切られないで繋がってしまう。\n",
    "                #そのため、改行コードを文字列brに変換して後でsplitする\n",
    "                f = urlopen(url)\n",
    "                html = f.read()\n",
    "                html = html.replace(b'<br />', b'br')\n",
    "                dfs = pd.read_html(html)\n",
    "\n",
    "                #dfsの1番目に単勝〜馬連、2番目にワイド〜三連単がある\n",
    "                df = pd.concat([dfs[1], dfs[2]])\n",
    "\n",
    "                df.index = [race_id] * len(df)\n",
    "                return_tables[race_id] = df\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except AttributeError: #存在しないrace_idでAttributeErrorになるページもあるので追加\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる\n",
    "        return_tables_df = pd.concat([return_tables[key] for key in return_tables])\n",
    "        return return_tables_df\n",
    "    \n",
    "    @property\n",
    "    def fukusho(self):\n",
    "        fukusho = self.return_tables[self.return_tables[0]=='複勝'][[1,2]]\n",
    "        wins = fukusho[1].str.split('br', expand=True)[[0,1,2]]\n",
    "        \n",
    "        wins.columns = ['win_0', 'win_1', 'win_2']\n",
    "        returns = fukusho[2].str.split('br', expand=True)[[0,1,2]]\n",
    "        returns.columns = ['return_0', 'return_1', 'return_2']\n",
    "        \n",
    "        df = pd.concat([wins, returns], axis=1)\n",
    "        for column in df.columns:\n",
    "            df[column] = df[column].str.replace(',', '')\n",
    "        return df.fillna(0).astype(int)\n",
    "    \n",
    "    @property\n",
    "    def tansho(self):\n",
    "        tansho = self.return_tables[self.return_tables[0]=='単勝'][[1,2]]\n",
    "        tansho.columns = ['win', 'return']\n",
    "        \n",
    "        for column in tansho.columns:\n",
    "            tansho[column] = pd.to_numeric(tansho[column], errors='coerce')\n",
    "            \n",
    "        return tansho\n",
    "    \n",
    "    @property\n",
    "    def umaren(self):\n",
    "        umaren = self.return_tables[self.return_tables[0]=='馬連'][[1,2]]\n",
    "        wins = umaren[1].str.split('-', expand=True)[[0,1]].add_prefix('win_')\n",
    "        return_ = umaren[2].rename('return')  \n",
    "        df = pd.concat([wins, return_], axis=1)        \n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    \n",
    "    @property\n",
    "    def umatan(self):\n",
    "        umatan = self.return_tables[self.return_tables[0]=='馬単'][[1,2]]\n",
    "        wins = umatan[1].str.split('→', expand=True)[[0,1]].add_prefix('win_')\n",
    "        return_ = umatan[2].rename('return')  \n",
    "        df = pd.concat([wins, return_], axis=1)        \n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    \n",
    "    @property\n",
    "    def wide(self):\n",
    "        wide = self.return_tables[self.return_tables[0]=='ワイド'][[1,2]]\n",
    "        wins = wide[1].str.split('br', expand=True)[[0,1,2]]\n",
    "        wins = wins.stack().str.split('-', expand=True).add_prefix('win_')\n",
    "        return_ = wide[2].str.split('br', expand=True)[[0,1,2]]\n",
    "        return_ = return_.stack().rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x: pd.to_numeric(x.str.replace(',',''), errors='coerce'))\n",
    "    \n",
    "    @property\n",
    "    def sanrentan(self):\n",
    "        rentan = self.return_tables[self.return_tables[0]=='三連単'][[1,2]]\n",
    "        wins = rentan[1].str.split('→', expand=True)[[0,1,2]].add_prefix('win_')\n",
    "        return_ = rentan[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1) \n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    \n",
    "    @property\n",
    "    def sanrenpuku(self):\n",
    "        renpuku = self.return_tables[self.return_tables[0]=='三連複'][[1,2]]\n",
    "        wins = renpuku[1].str.split('-', expand=True)[[0,1,2]].add_prefix('win_')\n",
    "        return_ = renpuku[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1) \n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, return_tables_path_list):\n",
    "        self.model = model\n",
    "        self.rt = Return.read_pickle(return_tables_path_list)\n",
    "        self.fukusho = self.rt.fukusho\n",
    "        self.tansho = self.rt.tansho\n",
    "        self.umaren = self.rt.umaren\n",
    "        self.umatan = self.rt.umatan\n",
    "        self.wide = self.rt.wide\n",
    "        self.sanrentan = self.rt.sanrentan\n",
    "        self.sanrenpuku = self.rt.sanrenpuku\n",
    "    \n",
    "    #3着以内に入る確率を予測\n",
    "    def predict_proba(self, X, train=True, std=True, minmax=False):\n",
    "        if train:\n",
    "            proba = pd.Series(\n",
    "                self.model.predict_proba(X.drop(['単勝'], axis=1))[:, 1], index=X.index\n",
    "            )\n",
    "        else:\n",
    "            proba = pd.Series(\n",
    "                self.model.predict_proba(X, axis=1)[:, 1], index=X.index\n",
    "            )\n",
    "        if std:\n",
    "            #レース内で標準化して、相対評価する。「レース内偏差値」みたいなもの。\n",
    "            standard_scaler = lambda x: (x - x.mean()) / x.std(ddof=0)\n",
    "            proba = proba.groupby(level=0).transform(standard_scaler)\n",
    "        if minmax:\n",
    "            #データ全体を0~1にする\n",
    "            proba = (proba - proba.min()) / (proba.max() - proba.min())\n",
    "        return proba\n",
    "    \n",
    "    #0か1かを予測\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        y_pred = self.predict_proba(X)\n",
    "        self.proba = y_pred\n",
    "        return [0 if p<threshold else 1 for p in y_pred]\n",
    "    \n",
    "    def score(self, y_true, X):\n",
    "        return roc_auc_score(y_true, self.predict_proba(X))\n",
    "    \n",
    "    def feature_importance(self, X, n_display=20):\n",
    "        importances = pd.DataFrame({\"features\": X.columns, \n",
    "                                    \"importance\": self.model.feature_importances_})\n",
    "        return importances.sort_values(\"importance\", ascending=False)[:n_display]\n",
    "    \n",
    "    def pred_table(self, X, threshold=0.5, bet_only=True):\n",
    "        pred_table = X.copy()[['馬番', '単勝']]\n",
    "        pred_table['pred'] = self.predict(X, threshold)\n",
    "        pred_table['score'] = self.proba\n",
    "        if bet_only:\n",
    "            return pred_table[pred_table['pred']==1][['馬番', '単勝', 'score']]\n",
    "        else:\n",
    "            return pred_table[['馬番', '単勝', 'score', 'pred']]\n",
    "        \n",
    "    def bet(self, race_id, kind, umaban, amount):\n",
    "        if kind == 'fukusho':\n",
    "            rt_1R = self.fukusho.loc[race_id]\n",
    "            return_ = (rt_1R[['win_0', 'win_1', 'win_2']]==umaban).values * \\\n",
    "                rt_1R[['return_0', 'return_1', 'return_2']].values * amount/100\n",
    "            return_ = np.sum(return_)\n",
    "        if kind == 'tansho':\n",
    "            rt_1R = self.tansho.loc[race_id]\n",
    "            return_ = (rt_1R['win']==umaban) * rt_1R['return'] * amount/100\n",
    "        if kind == 'umaren':\n",
    "            rt_1R = self.umaren.loc[race_id]\n",
    "            return_ = (set(rt_1R[['win_0', 'win_1']]) == set(umaban)) \\\n",
    "                * rt_1R['return']/100 * amount\n",
    "        if kind == 'umatan':\n",
    "            rt_1R = self.umatan.loc[race_id]\n",
    "            return_ = (list(rt_1R[['win_0', 'win_1']]) == list(umaban))\\\n",
    "                * rt_1R['return']/100 * amount\n",
    "        if kind == 'wide':\n",
    "            rt_1R = self.wide.loc[race_id]\n",
    "            return_ = (rt_1R[['win_0', 'win_1']].\\\n",
    "                           apply(lambda x: set(x)==set(umaban), axis=1)) \\\n",
    "                * rt_1R['return']/100 * amount\n",
    "            return_ = return_.sum()\n",
    "        if kind == 'sanrentan':\n",
    "            rt_1R = self.sanrentan.loc[race_id]\n",
    "            return_ = (list(rt_1R[['win_0', 'win_1', 'win_2']]) == list(umaban)) * \\\n",
    "                rt_1R['return']/100 * amount\n",
    "        if kind == 'sanrenpuku':\n",
    "            rt_1R = self.sanrenpuku.loc[race_id]\n",
    "            return_ = (set(rt_1R[['win_0', 'win_1', 'win_2']]) == set(umaban)) \\\n",
    "                * rt_1R['return']/100 * amount\n",
    "        if not (return_ >= 0):\n",
    "                return_ = amount\n",
    "        return return_\n",
    "        \n",
    "    def fukusho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(np.sum([\n",
    "                self.bet(race_id, 'fukusho', umaban, 1) for umaban in preds['馬番']\n",
    "            ]))\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def tansho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        self.sample = pred_table\n",
    "        n_bets = len(pred_table)\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(\n",
    "                np.sum([self.bet(race_id, 'tansho', umaban, 1) for umaban in preds['馬番']])\n",
    "            )\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def tansho_return_proper(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(\n",
    "                np.sum(preds.apply(lambda x: self.bet(\n",
    "                    race_id, 'tansho', x['馬番'], 1/x['単勝']), axis=1)))\n",
    "        \n",
    "        bet_money = (1 / pred_table['単勝']).sum()\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / bet_money\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / bet_money\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def umaren_box(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'umaren', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def umatan_box(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue   \n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in permutations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'umatan', umaban, 1)\n",
    "                    n_bets += 1\n",
    "            return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def wide_box(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'wide', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std  \n",
    "        \n",
    "    def sanrentan_box(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            if len(preds)<3:\n",
    "                continue\n",
    "            else:\n",
    "                for umaban in permutations(preds['馬番'], 3):\n",
    "                    return_ += self.bet(race_id, 'sanrentan', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def sanrenpuku_box(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            if len(preds)<3:\n",
    "                continue\n",
    "            else:\n",
    "                for umaban in combinations(preds['馬番'], 3):\n",
    "                    return_ += self.bet(race_id, 'sanrenpuku', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def umaren_nagashi(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                    .iloc[1:(n_aite+1)]['馬番']\n",
    "                return_ = preds_aite.map(\n",
    "                    lambda x: self.bet(\n",
    "                        race_id, 'umaren', [preds_jiku['馬番'].values[0], x], 1\n",
    "                    )\n",
    "                ).sum()\n",
    "                n_bets += n_aite\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'umaren', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def umatan_nagashi(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                    .iloc[1:(n_aite+1)]['馬番']\n",
    "                return_ = preds_aite.map(\n",
    "                    lambda x: self.bet(\n",
    "                        race_id, 'umatan', [preds_jiku['馬番'].values[0], x], 1\n",
    "                    )\n",
    "                ).sum()\n",
    "                n_bets += n_aite\n",
    "                \n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in permutations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'umatan', umaban, 1)\n",
    "                    n_bets += 1\n",
    "            return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def wide_nagashi(self, X, threshold=0.5, n_aite=5):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                    .iloc[1:(n_aite+1)]['馬番']\n",
    "                return_ = preds_aite.map(\n",
    "                    lambda x: self.bet(\n",
    "                        race_id, 'wide', [preds_jiku['馬番'].values[0], x], 1\n",
    "                    )\n",
    "                ).sum()\n",
    "                n_bets += len(preds_aite)\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku['馬番'], 2):\n",
    "                    return_ += self.bet(race_id, 'wide', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def sanrentan_nagashi(self, X, threshold = 1.5, n_aite=7):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only = False)\n",
    "        n_bets = 0\n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) == 2:\n",
    "                preds_aite = preds.sort_values('score', ascending = False)\\\n",
    "                    .iloc[2:(n_aite+2)]['馬番']\n",
    "                return_ = preds_aite.map(\n",
    "                    lambda x: self.bet(\n",
    "                        race_id, 'sanrentan',\n",
    "                        np.append(preds_jiku['馬番'].values, x),\n",
    "                        1\n",
    "                    )\n",
    "                ).sum()\n",
    "                n_bets += len(preds_aite)\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 3:\n",
    "                return_ = 0\n",
    "                for umaban in permutations(preds_jiku['馬番'], 3):\n",
    "                    return_ += self.bet(race_id, 'sanrentan', umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        return n_bets, return_rate, n_hits, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11Rの日本ダービーの出馬表をスクレイピング\n",
    "def current_race(race_id, month, day):\n",
    "    race_id = str(race_id)\n",
    "    date = '2023' + str(month).zfill(2) + str(day).zfill(2)\n",
    "    st = ShutubaTable.scrape([race_id], date)\n",
    "    #データ加工\n",
    "    st.preprocessing() #前処理\n",
    "    st.merge_horse_results(hr) #馬の過去成績結合\n",
    "    st.merge_peds(p.peds_e) #血統データ結合\n",
    "    st.process_categorical(r.le_horse, r.le_jockey, r.data_h) #カテゴリ変数処理\n",
    "    today = st.data_c.copy()\n",
    "    today.drop('date', axis=1, inplace=True)\n",
    "    pred = lgb_clf.predict_proba(today)[:, 1]\n",
    "    pred_data = pd.DataFrame({'pred': pred}, index=[today.馬番])\n",
    "    \n",
    "    return pred_data.sort_values('pred', ascending=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf20e40619747fd830de238f69ca74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e21ad486e384082abbb92222ae8e7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d8b72545d14d4f893a276252139d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78409328e6f044dabffa8953f916ee7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e856f4b5bb4c9ba52597372be1ecc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1dacbe72ff143f29833ccaa9b4e50e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06230f1041d4791be4e11a0f61a35c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f73453e1a9e471c9cc192ec1bcd2696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bc1bda6d864904ad974500f2c6b353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a229a91e044e9390572d9fb5110ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eab4eee1f354bf4a779a8f1e00da103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534617b890d04a949e9515c72eb34860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokyo = current_race(202305030611, 6, 18)\n",
    "hanshin = current_race(202309030611, 6, 18)\n",
    "hakodate = current_race(202302010411, 6, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>馬番</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.242886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.242886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.242886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.242886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.232887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.232085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.232085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.232085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.223658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.223658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.221014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.221014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.211899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred\n",
       "馬番          \n",
       "3   0.242886\n",
       "9   0.242886\n",
       "12  0.242886\n",
       "13  0.242886\n",
       "14  0.242886\n",
       "5   0.232887\n",
       "1   0.232085\n",
       "2   0.232085\n",
       "4   0.232085\n",
       "7   0.232085\n",
       "8   0.223658\n",
       "15  0.223658\n",
       "6   0.221014\n",
       "11  0.221014\n",
       "10  0.211899"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>馬番</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.242886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.242886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.223436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.216272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.216272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.216272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.213187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.210189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.210189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.208365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.205523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred\n",
       "馬番          \n",
       "4   0.242886\n",
       "9   0.242886\n",
       "1   0.229987\n",
       "7   0.223436\n",
       "3   0.221014\n",
       "11  0.216272\n",
       "12  0.216272\n",
       "13  0.216272\n",
       "8   0.213187\n",
       "2   0.210189\n",
       "10  0.210189\n",
       "5   0.208365\n",
       "6   0.205523"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hanshin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>馬番</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.232085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.232085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.225581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.223658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.223658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.223436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.221119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.221014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.213187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.213187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.213187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.210189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.205523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.198641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred\n",
       "馬番          \n",
       "6   0.232085\n",
       "10  0.232085\n",
       "5   0.225581\n",
       "3   0.223658\n",
       "7   0.223658\n",
       "4   0.223436\n",
       "11  0.223436\n",
       "13  0.221119\n",
       "12  0.221014\n",
       "8   0.213187\n",
       "14  0.213187\n",
       "16  0.213187\n",
       "1   0.210189\n",
       "2   0.210189\n",
       "9   0.205523\n",
       "15  0.198641"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hakodate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>date</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>年齢</th>\n",
       "      <th>...</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>ground_state_良</th>\n",
       "      <th>ground_state_稍重</th>\n",
       "      <th>ground_state_重</th>\n",
       "      <th>ground_state_不良</th>\n",
       "      <th>性_牝</th>\n",
       "      <th>性_牡</th>\n",
       "      <th>性_セ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>8710</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>10340</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>10613</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>9222</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701010101</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>9020</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202306030412</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>28862</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202306030412</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>30769</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202306030412</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>16718</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202306030412</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>22122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202306030412</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>24039</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270254 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              枠番  馬番    斤量    単勝  course_len       date horse_id jockey_id   \n",
       "201701010101   3   3  54.0   3.0        18.0 2017-07-29     8710        67  \\\n",
       "201701010101   5   5  54.0   1.5        18.0 2017-07-29    10340       197   \n",
       "201701010101   7   7  54.0   6.2        18.0 2017-07-29    10613        28   \n",
       "201701010101   1   1  54.0  31.1        18.0 2017-07-29     9222         7   \n",
       "201701010101   2   2  53.0  22.8        18.0 2017-07-29     9020       117   \n",
       "...           ..  ..   ...   ...         ...        ...      ...       ...   \n",
       "202306030412   2   3  56.0   2.9        12.0 2023-04-02    28862       134   \n",
       "202306030412   4   8  53.0  24.2        12.0 2023-04-02    30769       169   \n",
       "202306030412   7  13  56.0  22.9        12.0 2023-04-02    16718       148   \n",
       "202306030412   2   4  58.0  59.1        12.0 2023-04-02    22122         1   \n",
       "202306030412   1   1  58.0  28.4        12.0 2023-04-02    24039       133   \n",
       "\n",
       "              rank  年齢  ...  race_type_芝  race_type_ダート  race_type_障害   \n",
       "201701010101     1   2  ...         True          False         False  \\\n",
       "201701010101     1   2  ...         True          False         False   \n",
       "201701010101     1   2  ...         True          False         False   \n",
       "201701010101     0   2  ...         True          False         False   \n",
       "201701010101     0   2  ...         True          False         False   \n",
       "...            ...  ..  ...          ...            ...           ...   \n",
       "202306030412     0   4  ...        False           True         False   \n",
       "202306030412     0   4  ...        False           True         False   \n",
       "202306030412     0   7  ...        False           True         False   \n",
       "202306030412     0   6  ...        False           True         False   \n",
       "202306030412     0   5  ...        False           True         False   \n",
       "\n",
       "              ground_state_良  ground_state_稍重  ground_state_重   \n",
       "201701010101            True            False           False  \\\n",
       "201701010101            True            False           False   \n",
       "201701010101            True            False           False   \n",
       "201701010101            True            False           False   \n",
       "201701010101            True            False           False   \n",
       "...                      ...              ...             ...   \n",
       "202306030412            True            False           False   \n",
       "202306030412            True            False           False   \n",
       "202306030412            True            False           False   \n",
       "202306030412            True            False           False   \n",
       "202306030412            True            False           False   \n",
       "\n",
       "              ground_state_不良    性_牝    性_牡    性_セ  \n",
       "201701010101            False   True  False  False  \n",
       "201701010101            False  False   True  False  \n",
       "201701010101            False  False   True  False  \n",
       "201701010101            False  False   True  False  \n",
       "201701010101            False  False   True  False  \n",
       "...                       ...    ...    ...    ...  \n",
       "202306030412            False   True  False  False  \n",
       "202306030412            False   True  False  False  \n",
       "202306030412            False  False   True  False  \n",
       "202306030412            False  False   True  False  \n",
       "202306030412            False  False   True  False  \n",
       "\n",
       "[270254 rows x 188 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "9\n",
      "9\n",
      "14\n",
      "18\n",
      "11\n",
      "24\n",
      "18\n",
      "11\n",
      "13\n",
      "19\n",
      "36\n",
      "44\n",
      "51\n",
      "34\n",
      "38\n",
      "53\n",
      "56\n",
      "62\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 20000, 1000):\n",
    "    d1 = pd.read_pickle(f'beta/horse_data/horse_result{i}.pickle')\n",
    "    d2 = pd.read_pickle(f'beta/horse_data_raceID_added_ver2/horse_result{i}.pickle')\n",
    "    print(len(d2)-len(d1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
